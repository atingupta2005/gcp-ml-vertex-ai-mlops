{"cells": [{"cell_type": "markdown", "id": "46a2f98c", "metadata": {"tags": []}, "source": ["\n", "# 05 - Vertex AI > Notebooks - Models Built in Notebooks with Tensorflow\n", "\n", ">**NOTE:** The notebooks in the `05 - TensorFlow` series demonstrate training, serving and operations for TensorFlow models and take advantage of [Vertex AI TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) to track training across experiments.  Running these notebooks will create a Vertex AI TensorBoard instance which previously (before August 2023) had a subscription cost but is now priced based on storage of which this notebook will create minimal size (<2MB). - [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing#tensorboard).\n", "\n", "---\n", "---\n", "**Changes In Progress**\n", "\n", "Every attempt is being made to ensure the public version of this notebook runs without error while the follow enhancements are being made:\n", "- ~~The workflow of the notebook is being adapted to a Kubeflow Pipeline running on Vertex AI Pipelines~~\n", "- Including Evaluation data within Vertex AI Model Registry\n", "- Update the Vertex AI Experiments integration which has been great simplified within the API over the past few months\n", "- add client library reference links to each section\n", "\n", "Order: notebook 05 and 05a will be updated first.  Then 05b-05i will follow quickly.\n", "\n", "This note will be removed once these changes are complete.\n", "\n", "---\n", "---\n", "\n", "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n", "\n", "This notebook shows training a model directly within the runtime of the notebook environment.  Then the model is saved and moved to GCS for deployment to a Vertex AI > Endpoint for online predictions.  The model training is done with [Tensorflow](https://www.tensorflow.org/), specifically [Keras](https://keras.io/), and was designed to show a neural network approach to logistic regression.  The training data batches are read from BigQuery using [Tensorflow I/O](https://www.tensorflow.org/io).\n", "\n", "The other notebooks in this series (`05a-05i`) show how to move the training into a managed compute environment using Vertex AI > Training.  The first step to being able to use a training job is converting the code in this notebook into a training script.  This processs is covered in:\n", "- [05 - Vertex AI Custom Model - TensorFlow - Notebook to Script.ipynb](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Script.ipynb)\n", "- [05 - Vertex AI Custom Model - TensorFlow - Notebook to Hyperparameter Tuning Script.ipynb](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Hyperparameter%20Tuning%20Script.ipynb)\n", "\n", "**Video Walkthrough of this notebook:**\n", "\n", "Includes conversational walkthrough and more explanatory information than the notebook:\n", "\n", "<p align=\"center\" width=\"100%\"><center><a href=\"https://youtu.be/-5E3hWfsB4I\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"../architectures/thumbnails/playbutton/05.png\" width=\"40%\"></a></center></p>\n", "\n", "**Prerequisites:**\n", "- [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)\n", "\n", "**Resources:**\n", "-  [BigQuery Tensorflow Reader](https://www.tensorflow.org/io/tutorials/bigquery)\n", "-  [Keras Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n", "   -  [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n", "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n", "-  [Tensorflow Python Client](https://www.tensorflow.org/api_docs/python/tf)\n", "-  [Tensorflow I/O Python Client](https://www.tensorflow.org/io/api_docs/python/tfio/bigquery)\n", "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n", "- Pre-built Containers for Vertex AI\n", "    - [Training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n", "    - [Prediction & Explaination](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)\n", "\n", "**Conceptual Flow & Workflow**\n", "<p align=\"center\">\n", "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05_arch.png\" width=\"45%\">\n", "&nbsp; &nbsp; &nbsp; &nbsp;\n", "  <img alt=\"Workflow\" src=\"../architectures/slides/05_console.png\" width=\"45%\">\n", "</p>"]}, {"cell_type": "markdown", "id": "422f3a1c-7fb3-4074-a62f-8e5d7b64eaf4", "metadata": {}, "source": ["---\n", "## Colab Setup\n", "\n", "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) and run the cells in this section.  Otherwise, skip this section.\n", "\n", "This cell will authenticate to GCP (follow prompts in the popup)."]}, {"cell_type": "code", "execution_count": 1, "id": "48e5f635-a376-47ae-90e0-6cfd702260c6", "metadata": {}, "outputs": [], "source": ["PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"]}, {"cell_type": "code", "execution_count": 473, "id": "77f641a0-6361-40e5-8a82-c97065a82b00", "metadata": {}, "outputs": [], "source": ["try:\n", "    import google.colab\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    !gcloud config set project {PROJECT_ID}\n", "except Exception:\n", "    pass"]}, {"cell_type": "markdown", "id": "c8bcf1b2", "metadata": {}, "source": ["---\n", "## Setup"]}, {"cell_type": "markdown", "id": "10e366e2", "metadata": {}, "source": ["inputs:"]}, {"cell_type": "code", "execution_count": 1, "id": "918de403-af6d-44ff-9f05-a963b392ba7f", "metadata": {}, "outputs": [{"data": {"text/plain": ["'statmike-mlops-349915'"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["project = !gcloud config get-value project\n", "PROJECT_ID = project[0]\n", "PROJECT_ID"]}, {"cell_type": "code", "execution_count": 2, "id": "614de332", "metadata": {}, "outputs": [], "source": ["REGION = 'us-central1'\n", "EXPERIMENT = '05'\n", "SERIES = '05'\n", "\n", "# source data\n", "BQ_PROJECT = PROJECT_ID\n", "BQ_DATASET = 'fraud'\n", "BQ_TABLE = 'fraud_prepped'\n", "\n", "# Resources\n", "DEPLOY_COMPUTE = 'n1-standard-4'\n", "DEPLOY_IMAGE='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n", "\n", "# Model Training\n", "VAR_TARGET = 'Class'\n", "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters\n", "EPOCHS = 4\n", "BATCH_SIZE = 100"]}, {"cell_type": "code", "execution_count": 50, "id": "41be9395-f783-4f2b-8354-8a38740514b0", "metadata": {}, "outputs": [], "source": ["#!pip install tensorflow==2.10.0 tensorflow-io==0.27.0"]}, {"cell_type": "markdown", "id": "a92f2936", "metadata": {}, "source": ["packages:"]}, {"cell_type": "code", "execution_count": 3, "id": "986e7804", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:25:27.949604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n", "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n", "2023-09-28 23:25:28.185143: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n", "2023-09-28 23:25:29.206932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n", "2023-09-28 23:25:29.207114: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n", "2023-09-28 23:25:29.207127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}], "source": ["from google.cloud import bigquery\n", "\n", "from tensorflow.python.framework import dtypes\n", "from tensorflow_io.bigquery import BigQueryClient\n", "import tensorflow as tf\n", "\n", "from google.cloud import aiplatform\n", "from datetime import datetime\n", "import os\n", "\n", "from google.protobuf import json_format\n", "from google.protobuf.struct_pb2 import Value\n", "import json\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn import metrics as metrics"]}, {"cell_type": "markdown", "id": "139d3707", "metadata": {}, "source": ["clients:"]}, {"cell_type": "code", "execution_count": 4, "id": "fdbc3411", "metadata": {}, "outputs": [], "source": ["aiplatform.init(project = PROJECT_ID, location = REGION)\n", "bq = bigquery.Client(project = PROJECT_ID)"]}, {"cell_type": "markdown", "id": "6f4052df", "metadata": {}, "source": ["parameters:"]}, {"cell_type": "code", "execution_count": 5, "id": "ddd94e3a", "metadata": {}, "outputs": [], "source": ["TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n", "BUCKET = PROJECT_ID\n", "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n", "DIR = f\"temp/{EXPERIMENT}\""]}, {"cell_type": "markdown", "id": "de43acbc", "metadata": {}, "source": ["environment:"]}, {"cell_type": "code", "execution_count": 6, "id": "a92f3b28", "metadata": {}, "outputs": [], "source": ["!rm -rf {DIR}\n", "!mkdir -p {DIR}"]}, {"cell_type": "markdown", "id": "4ba31b6b-ff8a-4786-b360-cd936dbf615d", "metadata": {}, "source": ["Experiment Tracking:"]}, {"cell_type": "code", "execution_count": 7, "id": "e3f1b204-0579-40f4-9a1f-b7b9c94b7d1f", "metadata": {}, "outputs": [], "source": ["FRAMEWORK = 'tf'\n", "TASK = 'classification'\n", "MODEL_TYPE = 'dnn'\n", "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n", "RUN_NAME = f'run-{TIMESTAMP}'"]}, {"cell_type": "markdown", "id": "b5f08321-ae93-4d77-be62-7d037546a9b6", "metadata": {"tags": []}, "source": ["---\n", "## Get Vertex AI Experiments Tensorboard Instance Name\n", "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.tensorflow.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n", "\n", "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n", "\n", "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"]}, {"cell_type": "code", "execution_count": 8, "id": "0c0cfc16", "metadata": {}, "outputs": [], "source": ["tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n", "if tb:\n", "    tb = tb[0]\n", "else: \n", "    tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})"]}, {"cell_type": "code", "execution_count": 9, "id": "e7bdbeab-553f-4715-980e-da14bd9c264a", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["'projects/1026793852137/locations/us-central1/tensorboards/7876136041294331904'"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["tb.resource_name"]}, {"cell_type": "markdown", "id": "508436e8-3869-41d4-8163-6931e74746e5", "metadata": {}, "source": ["---\n", "## Setup Vertex AI Experiments\n", "\n", "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n", "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n", "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n", "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"]}, {"cell_type": "markdown", "id": "8af8c686-2f32-449a-8b50-e54d227f5618", "metadata": {}, "source": ["Initialize the Experiment:"]}, {"cell_type": "code", "execution_count": 10, "id": "77250775-ba29-45dc-8fbc-bd3bac659bea", "metadata": {}, "outputs": [], "source": ["aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)"]}, {"cell_type": "markdown", "id": "0e933951-dc2f-4dc6-9560-e3ec1f73b5b9", "metadata": {}, "source": ["Create an experiment run:"]}, {"cell_type": "code", "execution_count": 11, "id": "c2af6981-3dd1-40c2-aac8-96f65e1962ea", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Associating projects/1026793852137/locations/us-central1/metadataStores/default/contexts/experiment-05-05-tf-classification-dnn-run-20230928232537 to Experiment: experiment-05-05-tf-classification-dnn\n", "Starting a new run.\n"]}], "source": ["if RUN_NAME in [run.name for run in aiplatform.ExperimentRun.list(experiment = EXPERIMENT_NAME)]:\n", "    expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)\n", "    print('This run already exist with, using previous.')\n", "else:\n", "    expRun = aiplatform.ExperimentRun.create(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)\n", "    print('Starting a new run.')"]}, {"cell_type": "markdown", "id": "1ad1abf6-aa21-4644-928d-6e44efe59719", "metadata": {}, "source": ["Log parameters to the experiment run:"]}, {"cell_type": "code", "execution_count": 12, "id": "89c0e7d4-921a-4f7f-8e91-ac703897b9d2", "metadata": {}, "outputs": [], "source": ["expRun.log_params({'experiment': EXPERIMENT, 'series': SERIES, 'project_id': PROJECT_ID})"]}, {"cell_type": "markdown", "id": "eaf48dc3-cdbd-4e34-be4d-33c7563dbd33", "metadata": {}, "source": ["---\n", "## Training Data\n", "In this exercise the data source is a table in Google BigQuery.  While it is possible to bring the entire table into the local notebook as a Pandas dataframe, it is not a scalable solution for very large training tables.  In this section the connection to BigQuery is done using Tensorflow I/O to read batches of training data in parallel during model training."]}, {"cell_type": "markdown", "id": "5f93fde9", "metadata": {}, "source": ["### Data Schema\n", "Using BigQueries Information_Schema is an easy way to quickly retrieve the column information about our training data.  In this case we need the column names and data types to setup the data reading and the model inputs.  This section retrieves the column information for the training table source."]}, {"cell_type": "code", "execution_count": 13, "id": "6edde19f", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>table_catalog</th>\n", "      <th>table_schema</th>\n", "      <th>table_name</th>\n", "      <th>column_name</th>\n", "      <th>ordinal_position</th>\n", "      <th>is_nullable</th>\n", "      <th>data_type</th>\n", "      <th>is_generated</th>\n", "      <th>generation_expression</th>\n", "      <th>is_stored</th>\n", "      <th>is_hidden</th>\n", "      <th>is_updatable</th>\n", "      <th>is_system_defined</th>\n", "      <th>is_partitioning_column</th>\n", "      <th>clustering_ordinal_position</th>\n", "      <th>collation_name</th>\n", "      <th>column_default</th>\n", "      <th>rounding_mode</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>Time</td>\n", "      <td>1</td>\n", "      <td>YES</td>\n", "      <td>INT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V1</td>\n", "      <td>2</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V2</td>\n", "      <td>3</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V3</td>\n", "      <td>4</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V4</td>\n", "      <td>5</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>5</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V5</td>\n", "      <td>6</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>6</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V6</td>\n", "      <td>7</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>7</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V7</td>\n", "      <td>8</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>8</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V8</td>\n", "      <td>9</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>9</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V9</td>\n", "      <td>10</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>10</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V10</td>\n", "      <td>11</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>11</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V11</td>\n", "      <td>12</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>12</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V12</td>\n", "      <td>13</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>13</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V13</td>\n", "      <td>14</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>14</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V14</td>\n", "      <td>15</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>15</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V15</td>\n", "      <td>16</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>16</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V16</td>\n", "      <td>17</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>17</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V17</td>\n", "      <td>18</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>18</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V18</td>\n", "      <td>19</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>19</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V19</td>\n", "      <td>20</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>20</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V20</td>\n", "      <td>21</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>21</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V21</td>\n", "      <td>22</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>22</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V22</td>\n", "      <td>23</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>23</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V23</td>\n", "      <td>24</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>24</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V24</td>\n", "      <td>25</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>25</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V25</td>\n", "      <td>26</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>26</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V26</td>\n", "      <td>27</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>27</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V27</td>\n", "      <td>28</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>28</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>V28</td>\n", "      <td>29</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>29</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>Amount</td>\n", "      <td>30</td>\n", "      <td>YES</td>\n", "      <td>FLOAT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>30</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>Class</td>\n", "      <td>31</td>\n", "      <td>YES</td>\n", "      <td>INT64</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>31</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>transaction_id</td>\n", "      <td>32</td>\n", "      <td>YES</td>\n", "      <td>STRING</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>32</th>\n", "      <td>statmike-mlops-349915</td>\n", "      <td>fraud</td>\n", "      <td>fraud_prepped</td>\n", "      <td>splits</td>\n", "      <td>33</td>\n", "      <td>YES</td>\n", "      <td>STRING</td>\n", "      <td>NEVER</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>None</td>\n", "      <td>NO</td>\n", "      <td>NO</td>\n", "      <td>&lt;NA&gt;</td>\n", "      <td>NULL</td>\n", "      <td>NULL</td>\n", "      <td>None</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["            table_catalog table_schema     table_name     column_name  \\\n", "0   statmike-mlops-349915        fraud  fraud_prepped            Time   \n", "1   statmike-mlops-349915        fraud  fraud_prepped              V1   \n", "2   statmike-mlops-349915        fraud  fraud_prepped              V2   \n", "3   statmike-mlops-349915        fraud  fraud_prepped              V3   \n", "4   statmike-mlops-349915        fraud  fraud_prepped              V4   \n", "5   statmike-mlops-349915        fraud  fraud_prepped              V5   \n", "6   statmike-mlops-349915        fraud  fraud_prepped              V6   \n", "7   statmike-mlops-349915        fraud  fraud_prepped              V7   \n", "8   statmike-mlops-349915        fraud  fraud_prepped              V8   \n", "9   statmike-mlops-349915        fraud  fraud_prepped              V9   \n", "10  statmike-mlops-349915        fraud  fraud_prepped             V10   \n", "11  statmike-mlops-349915        fraud  fraud_prepped             V11   \n", "12  statmike-mlops-349915        fraud  fraud_prepped             V12   \n", "13  statmike-mlops-349915        fraud  fraud_prepped             V13   \n", "14  statmike-mlops-349915        fraud  fraud_prepped             V14   \n", "15  statmike-mlops-349915        fraud  fraud_prepped             V15   \n", "16  statmike-mlops-349915        fraud  fraud_prepped             V16   \n", "17  statmike-mlops-349915        fraud  fraud_prepped             V17   \n", "18  statmike-mlops-349915        fraud  fraud_prepped             V18   \n", "19  statmike-mlops-349915        fraud  fraud_prepped             V19   \n", "20  statmike-mlops-349915        fraud  fraud_prepped             V20   \n", "21  statmike-mlops-349915        fraud  fraud_prepped             V21   \n", "22  statmike-mlops-349915        fraud  fraud_prepped             V22   \n", "23  statmike-mlops-349915        fraud  fraud_prepped             V23   \n", "24  statmike-mlops-349915        fraud  fraud_prepped             V24   \n", "25  statmike-mlops-349915        fraud  fraud_prepped             V25   \n", "26  statmike-mlops-349915        fraud  fraud_prepped             V26   \n", "27  statmike-mlops-349915        fraud  fraud_prepped             V27   \n", "28  statmike-mlops-349915        fraud  fraud_prepped             V28   \n", "29  statmike-mlops-349915        fraud  fraud_prepped          Amount   \n", "30  statmike-mlops-349915        fraud  fraud_prepped           Class   \n", "31  statmike-mlops-349915        fraud  fraud_prepped  transaction_id   \n", "32  statmike-mlops-349915        fraud  fraud_prepped          splits   \n", "\n", "    ordinal_position is_nullable data_type is_generated generation_expression  \\\n", "0                  1         YES     INT64        NEVER                  None   \n", "1                  2         YES   FLOAT64        NEVER                  None   \n", "2                  3         YES   FLOAT64        NEVER                  None   \n", "3                  4         YES   FLOAT64        NEVER                  None   \n", "4                  5         YES   FLOAT64        NEVER                  None   \n", "5                  6         YES   FLOAT64        NEVER                  None   \n", "6                  7         YES   FLOAT64        NEVER                  None   \n", "7                  8         YES   FLOAT64        NEVER                  None   \n", "8                  9         YES   FLOAT64        NEVER                  None   \n", "9                 10         YES   FLOAT64        NEVER                  None   \n", "10                11         YES   FLOAT64        NEVER                  None   \n", "11                12         YES   FLOAT64        NEVER                  None   \n", "12                13         YES   FLOAT64        NEVER                  None   \n", "13                14         YES   FLOAT64        NEVER                  None   \n", "14                15         YES   FLOAT64        NEVER                  None   \n", "15                16         YES   FLOAT64        NEVER                  None   \n", "16                17         YES   FLOAT64        NEVER                  None   \n", "17                18         YES   FLOAT64        NEVER                  None   \n", "18                19         YES   FLOAT64        NEVER                  None   \n", "19                20         YES   FLOAT64        NEVER                  None   \n", "20                21         YES   FLOAT64        NEVER                  None   \n", "21                22         YES   FLOAT64        NEVER                  None   \n", "22                23         YES   FLOAT64        NEVER                  None   \n", "23                24         YES   FLOAT64        NEVER                  None   \n", "24                25         YES   FLOAT64        NEVER                  None   \n", "25                26         YES   FLOAT64        NEVER                  None   \n", "26                27         YES   FLOAT64        NEVER                  None   \n", "27                28         YES   FLOAT64        NEVER                  None   \n", "28                29         YES   FLOAT64        NEVER                  None   \n", "29                30         YES   FLOAT64        NEVER                  None   \n", "30                31         YES     INT64        NEVER                  None   \n", "31                32         YES    STRING        NEVER                  None   \n", "32                33         YES    STRING        NEVER                  None   \n", "\n", "   is_stored is_hidden is_updatable is_system_defined is_partitioning_column  \\\n", "0       None        NO         None                NO                     NO   \n", "1       None        NO         None                NO                     NO   \n", "2       None        NO         None                NO                     NO   \n", "3       None        NO         None                NO                     NO   \n", "4       None        NO         None                NO                     NO   \n", "5       None        NO         None                NO                     NO   \n", "6       None        NO         None                NO                     NO   \n", "7       None        NO         None                NO                     NO   \n", "8       None        NO         None                NO                     NO   \n", "9       None        NO         None                NO                     NO   \n", "10      None        NO         None                NO                     NO   \n", "11      None        NO         None                NO                     NO   \n", "12      None        NO         None                NO                     NO   \n", "13      None        NO         None                NO                     NO   \n", "14      None        NO         None                NO                     NO   \n", "15      None        NO         None                NO                     NO   \n", "16      None        NO         None                NO                     NO   \n", "17      None        NO         None                NO                     NO   \n", "18      None        NO         None                NO                     NO   \n", "19      None        NO         None                NO                     NO   \n", "20      None        NO         None                NO                     NO   \n", "21      None        NO         None                NO                     NO   \n", "22      None        NO         None                NO                     NO   \n", "23      None        NO         None                NO                     NO   \n", "24      None        NO         None                NO                     NO   \n", "25      None        NO         None                NO                     NO   \n", "26      None        NO         None                NO                     NO   \n", "27      None        NO         None                NO                     NO   \n", "28      None        NO         None                NO                     NO   \n", "29      None        NO         None                NO                     NO   \n", "30      None        NO         None                NO                     NO   \n", "31      None        NO         None                NO                     NO   \n", "32      None        NO         None                NO                     NO   \n", "\n", "    clustering_ordinal_position collation_name column_default rounding_mode  \n", "0                          <NA>           NULL           NULL          None  \n", "1                          <NA>           NULL           NULL          None  \n", "2                          <NA>           NULL           NULL          None  \n", "3                          <NA>           NULL           NULL          None  \n", "4                          <NA>           NULL           NULL          None  \n", "5                          <NA>           NULL           NULL          None  \n", "6                          <NA>           NULL           NULL          None  \n", "7                          <NA>           NULL           NULL          None  \n", "8                          <NA>           NULL           NULL          None  \n", "9                          <NA>           NULL           NULL          None  \n", "10                         <NA>           NULL           NULL          None  \n", "11                         <NA>           NULL           NULL          None  \n", "12                         <NA>           NULL           NULL          None  \n", "13                         <NA>           NULL           NULL          None  \n", "14                         <NA>           NULL           NULL          None  \n", "15                         <NA>           NULL           NULL          None  \n", "16                         <NA>           NULL           NULL          None  \n", "17                         <NA>           NULL           NULL          None  \n", "18                         <NA>           NULL           NULL          None  \n", "19                         <NA>           NULL           NULL          None  \n", "20                         <NA>           NULL           NULL          None  \n", "21                         <NA>           NULL           NULL          None  \n", "22                         <NA>           NULL           NULL          None  \n", "23                         <NA>           NULL           NULL          None  \n", "24                         <NA>           NULL           NULL          None  \n", "25                         <NA>           NULL           NULL          None  \n", "26                         <NA>           NULL           NULL          None  \n", "27                         <NA>           NULL           NULL          None  \n", "28                         <NA>           NULL           NULL          None  \n", "29                         <NA>           NULL           NULL          None  \n", "30                         <NA>           NULL           NULL          None  \n", "31                         <NA>           NULL           NULL          None  \n", "32                         <NA>           NULL           NULL          None  "]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{BQ_TABLE}'\"\n", "schema = bq.query(query).to_dataframe()\n", "schema"]}, {"cell_type": "markdown", "id": "a968eba8", "metadata": {}, "source": ["### Number of Classes for the Label Column: VAR_TARGET\n", "This is a supervised learning example that classifies examples into the classes found in the label column stored in the variable `VAR_TARGET`."]}, {"cell_type": "code", "execution_count": 14, "id": "45fcc860", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Class</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>1</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["   Class\n", "0      0\n", "1      1"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["nclasses = bq.query(query = f'SELECT DISTINCT {VAR_TARGET} FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE {VAR_TARGET} is not null').to_dataframe()\n", "nclasses"]}, {"cell_type": "code", "execution_count": 15, "id": "88143160", "metadata": {}, "outputs": [{"data": {"text/plain": ["2"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["nclasses = nclasses.shape[0]\n", "nclasses"]}, {"cell_type": "code", "execution_count": 16, "id": "e6f1d194-d59f-41b9-90b3-5f1e15af4233", "metadata": {}, "outputs": [], "source": ["expRun.log_params({'data_source': f'bq://{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': VAR_TARGET})"]}, {"cell_type": "markdown", "id": "ce90cf60", "metadata": {}, "source": ["### Selected Columns and Data Types\n", "\n", "Use the the table schema to prepare the TensorFlow model inputs:\n", "- Omit unused columns\n", "- Create list of `selected_fields` from the training source\n", "- Define the data types, `output_types`, using the schema data and remapping to desired precision if needed"]}, {"cell_type": "code", "execution_count": 17, "id": "da81bb93", "metadata": {}, "outputs": [], "source": ["# Make a list of columns to omit\n", "OMIT = VAR_OMIT.split() + ['splits']\n", "\n", "# use schema to prepare a list of columns to read from BigQuery\n", "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n", "\n", "# all the columns in this data source are either float64 or int64\n", "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]"]}, {"cell_type": "markdown", "id": "8169327f", "metadata": {}, "source": ["---\n", "## Read From BigQuery Using TensorFlow I/O "]}, {"cell_type": "markdown", "id": "60ad3922-4ebe-4fc2-b08a-bc05019f3e57", "metadata": {}, "source": ["### Divide the inputs into features and target"]}, {"cell_type": "markdown", "id": "fa7456f0", "metadata": {}, "source": ["Define a function that remaps the input data for TensorFlow into:\n", "- features\n", "- `target` - one_hot encoded for multi-class classification and also works for binary classification"]}, {"cell_type": "code", "execution_count": 18, "id": "95911ae2", "metadata": {}, "outputs": [], "source": ["def transTable(row_dict):\n", "    target = row_dict.pop(VAR_TARGET)\n", "    target = tf.one_hot(tf.cast(target,tf.int64), nclasses)\n", "    target = tf.cast(target, tf.float32)\n", "    return(row_dict, target)"]}, {"cell_type": "markdown", "id": "73388e33", "metadata": {}, "source": ["### Setup Tensorflow I/O to Read Batches from BigQuery\n", "\n", "Setup TensorFlow_IO client > session > table + table.map\n", "- https://www.tensorflow.org/io/api_docs/python/tfio/bigquery/BigQueryClient"]}, {"cell_type": "code", "execution_count": 19, "id": "39dbdf21", "metadata": {}, "outputs": [], "source": ["def bq_reader(split):\n", "    reader = BigQueryClient()\n", "\n", "    training = reader.read_session(\n", "        parent = f\"projects/{PROJECT_ID}\",\n", "        project_id = BQ_PROJECT,\n", "        table_id = BQ_TABLE,\n", "        dataset_id = BQ_DATASET,\n", "        selected_fields = selected_fields,\n", "        output_types = output_types,\n", "        row_restriction = f\"splits='{split}'\",\n", "        requested_streams = 3\n", "    )\n", "    \n", "    return training.parallel_read_rows(sloppy = True, num_parallel_calls = tf.data.experimental.AUTOTUNE)"]}, {"cell_type": "code", "execution_count": 51, "id": "dd76b3b8-6fce-4ac7-9a91-d2d2c9864f11", "metadata": {}, "outputs": [], "source": ["#bq_reader('TRAIN')#[0]"]}, {"cell_type": "code", "execution_count": 22, "id": "02718964", "metadata": {}, "outputs": [], "source": ["train = bq_reader('TRAIN').prefetch(1).map(transTable).shuffle(BATCH_SIZE*10).batch(BATCH_SIZE)\n", "validate = bq_reader('VALIDATE').prefetch(1).map(transTable).batch(BATCH_SIZE)\n", "test = bq_reader('TEST').prefetch(1).map(transTable).batch(BATCH_SIZE)"]}, {"cell_type": "code", "execution_count": 23, "id": "1d17a7a5-d83c-4ba3-ae36-0c9d2aacc685", "metadata": {}, "outputs": [], "source": ["expRun.log_params({'training.batch_size': BATCH_SIZE, 'training.shuffle': 10*BATCH_SIZE, 'training.prefetch': 1})"]}, {"cell_type": "markdown", "id": "cfc84d95", "metadata": {}, "source": ["Review a single batch of the train data:"]}, {"cell_type": "code", "execution_count": 24, "id": "9666af2c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:26:28.048388: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:26:28.048431: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["features:\n", " ['Amount', 'Time', 'V1', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V2', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\n", "\n", "target:\n", " tf.Tensor(\n", "[[1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]\n", " [1. 0.]], shape=(10, 2), dtype=float32)\n"]}], "source": ["for features, target in train.take(1):\n", "    print('features:\\n',list(features.keys()))\n", "    print('\\ntarget:\\n',target[0:10])"]}, {"cell_type": "markdown", "id": "f359ac9a", "metadata": {}, "source": ["---\n", "## Define the Model: In The Notebook (local runtime)\n", "\n", "Define the Model:\n", "- Building the model using the [Keras functional api](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n", "- This is basically multi-class logistic regression where the feature space is mapped to the number of classes in the target by a [softmax activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax)\n", "- The [keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) is made up of `inputs` and `outputs`\n", "    - the inputs are a list of [keras.Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input) tensors that was constructed above\n", "    - the outputs are a group of [keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n", "        - connects each input to a [Dense layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) with units set to the number of features\n", "        - connecting to a [BatchNormalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)\n", "            - for each batch of inputs it scales each feature to have mean = 0 and standard deviation = 1 for the batch\n", "            - Note on Normalization - If you are using TensorFlow 2.6 or higher then you can also try a normalization layer with the [adapt method](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization#adapt) as a preprocessing layer (does not update during training).\n", "        - ending with a [Dense layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) with units set to the number of class levels in the target\n", "\n", "Adding metrics to the model:\n", "- Specifying 'accuracy' triggers conversion to [tf.keras.metrics.CategoricalAccuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalAccuracy) due to the loss function being [tf.keras.losses.CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)\n", "- If the target variable is highly imbalanced then it is good to consider the area under the precision-recall curve.  This is requested with [tf.keras.metrics.AUC(curve='PR')](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)"]}, {"cell_type": "code", "execution_count": 25, "id": "a3d3792d-c1ed-4a1b-9a39-f9d7ab1e00ac", "metadata": {}, "outputs": [], "source": ["# Logistic Regression\n", "\n", "# model input definitions\n", "feature_columns = {header: tf.feature_column.numeric_column(header) for header in selected_fields if header != VAR_TARGET}\n", "feature_layer_inputs = {header: tf.keras.layers.Input(shape = (1,), name = header) for header in selected_fields if header != VAR_TARGET}\n", "\n", "# feature columns to a Dense Feature Layer\n", "feature_layer_outputs = tf.keras.layers.DenseFeatures(feature_columns.values(), name = 'feature_layer')(feature_layer_inputs)\n", "\n", "# batch normalization of inputs\n", "normalized = tf.keras.layers.BatchNormalization(name = 'batch_normalization_layer')(feature_layer_outputs)\n", "\n", "# logistic - using softmax activation to nclasses\n", "logistic = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax, name = 'logistic')(normalized)\n", "\n", "# the model\n", "model = tf.keras.Model(\n", "    inputs = feature_layer_inputs,\n", "    outputs = logistic,\n", "    name = EXPERIMENT\n", ")\n", "\n", "# compile\n", "model.compile(\n", "    optimizer = tf.keras.optimizers.SGD(), #SGD or Adam\n", "    loss = tf.keras.losses.CategoricalCrossentropy(),\n", "    metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'PR', name = 'auprc')]\n", ")"]}, {"cell_type": "code", "execution_count": 26, "id": "9bb2b745-bc33-48ae-b173-8e0da35b3785", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Collecting graphviz\n", "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n", "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m957.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n", "\u001b[?25hInstalling collected packages: graphviz\n", "Successfully installed graphviz-0.20.1\n"]}], "source": ["!pip install graphviz"]}, {"cell_type": "code", "execution_count": 27, "id": "fad7763a-b857-41f7-9686-f95403e57b2b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]}], "source": ["tf.keras.utils.plot_model(model, rankdir='LR')"]}, {"cell_type": "code", "execution_count": 28, "id": "5071c936", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"05\"\n", "__________________________________________________________________________________________________\n", " Layer (type)                   Output Shape         Param #     Connected to                     \n", "==================================================================================================\n", " Amount (InputLayer)            [(None, 1)]          0           []                               \n", "                                                                                                  \n", " Time (InputLayer)              [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V1 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V10 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V11 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V12 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V13 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V14 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V15 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V16 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V17 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V18 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V19 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V2 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V20 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V21 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V22 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V23 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V24 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V25 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V26 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V27 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V28 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V3 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V4 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V5 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V6 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V7 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V8 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V9 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " feature_layer (DenseFeatures)  (None, 30)           0           ['Amount[0][0]',                 \n", "                                                                  'Time[0][0]',                   \n", "                                                                  'V1[0][0]',                     \n", "                                                                  'V10[0][0]',                    \n", "                                                                  'V11[0][0]',                    \n", "                                                                  'V12[0][0]',                    \n", "                                                                  'V13[0][0]',                    \n", "                                                                  'V14[0][0]',                    \n", "                                                                  'V15[0][0]',                    \n", "                                                                  'V16[0][0]',                    \n", "                                                                  'V17[0][0]',                    \n", "                                                                  'V18[0][0]',                    \n", "                                                                  'V19[0][0]',                    \n", "                                                                  'V2[0][0]',                     \n", "                                                                  'V20[0][0]',                    \n", "                                                                  'V21[0][0]',                    \n", "                                                                  'V22[0][0]',                    \n", "                                                                  'V23[0][0]',                    \n", "                                                                  'V24[0][0]',                    \n", "                                                                  'V25[0][0]',                    \n", "                                                                  'V26[0][0]',                    \n", "                                                                  'V27[0][0]',                    \n", "                                                                  'V28[0][0]',                    \n", "                                                                  'V3[0][0]',                     \n", "                                                                  'V4[0][0]',                     \n", "                                                                  'V5[0][0]',                     \n", "                                                                  'V6[0][0]',                     \n", "                                                                  'V7[0][0]',                     \n", "                                                                  'V8[0][0]',                     \n", "                                                                  'V9[0][0]']                     \n", "                                                                                                  \n", " batch_normalization_layer (Bat  (None, 30)          120         ['feature_layer[0][0]']          \n", " chNormalization)                                                                                 \n", "                                                                                                  \n", " logistic (Dense)               (None, 2)            62          ['batch_normalization_layer[0][0]\n", "                                                                 ']                               \n", "                                                                                                  \n", "==================================================================================================\n", "Total params: 182\n", "Trainable params: 122\n", "Non-trainable params: 60\n", "__________________________________________________________________________________________________\n"]}], "source": ["model.summary()"]}, {"cell_type": "markdown", "id": "4063ec71-6bdb-4660-8c36-e9a1ac4c294e", "metadata": {}, "source": ["---\n", "## Train The Model: In The Notebook (local runtime)"]}, {"cell_type": "markdown", "id": "5a1e7136", "metadata": {}, "source": ["Fit the Model:"]}, {"cell_type": "code", "execution_count": 29, "id": "e68eeeb2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Epoch 1/4\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:26:53.870422: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:26:53.870480: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["   2281/Unknown - 33s 13ms/step - loss: 0.0714 - accuracy: 0.9804 - auprc: 0.9962"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:27:26.265344: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:27:26.265403: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2281/2281 [==============================] - 38s 15ms/step - loss: 0.0714 - accuracy: 0.9804 - auprc: 0.9962 - val_loss: 0.0118 - val_accuracy: 0.9987 - val_auprc: 0.9993\n", "Epoch 2/4\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:27:30.209458: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:27:30.209520: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2281/2281 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9988 - auprc: 0.9995"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:28:00.498469: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:28:00.498527: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2281/2281 [==============================] - 34s 15ms/step - loss: 0.0091 - accuracy: 0.9988 - auprc: 0.9995 - val_loss: 0.0073 - val_accuracy: 0.9991 - val_auprc: 0.9994\n", "Epoch 3/4\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:28:11.159015: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:28:11.159078: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2278/2281 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9990 - auprc: 0.9995"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:28:40.852289: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:28:40.852349: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2281/2281 [==============================] - 34s 15ms/step - loss: 0.0065 - accuracy: 0.9990 - auprc: 0.9995 - val_loss: 0.0063 - val_accuracy: 0.9992 - val_auprc: 0.9995\n", "Epoch 4/4\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:28:45.358695: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:28:45.358774: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2271/2281 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9992 - auprc: 0.9995"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:29:15.623663: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:29:15.623722: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2281/2281 [==============================] - 35s 15ms/step - loss: 0.0055 - accuracy: 0.9992 - auprc: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9992 - val_auprc: 0.9995\n"]}], "source": ["# setup tensorboard logs and train\n", "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = os.path.join(DIR, \"logs\", f'{TIMESTAMP}'), histogram_freq=1)\n", "history = model.fit(train, epochs = EPOCHS, callbacks = [tensorboard_callback], validation_data = validate)"]}, {"cell_type": "code", "execution_count": 30, "id": "2e069d7f", "metadata": {}, "outputs": [{"data": {"text/plain": ["0.005465980619192123"]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["history.history['loss'][-1]"]}, {"cell_type": "code", "execution_count": 31, "id": "5a33acf8-7d0c-4270-b4a3-55a944c9d680", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'verbose': 1, 'epochs': 4, 'steps': None}"]}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": ["expRun.log_params({'training.epochs': history.params['epochs']})\n", "history.params"]}, {"cell_type": "markdown", "id": "1f5aa14e-ab43-49dc-b8d3-cbfc162d7b8f", "metadata": {}, "source": ["Log the time series metrics to the experiments TensorBoard:"]}, {"cell_type": "code", "execution_count": 32, "id": "6615073e-321a-4d9b-ad6b-a8e91fb48d73", "metadata": {}, "outputs": [], "source": ["for e in range(0, history.params['epochs']):\n", "    expRun.log_time_series_metrics(\n", "        {\n", "            'train_loss': history.history['loss'][e],\n", "            'train_accuracy': history.history['accuracy'][e],\n", "            'train_auprc': history.history['auprc'][e],\n", "            'val_loss': history.history['val_loss'][e],\n", "            'val_accuracy': history.history['val_accuracy'][e],\n", "            'val_auprc': history.history['val_auprc'][e]\n", "        }, step = e\n", "    )"]}, {"cell_type": "markdown", "id": "291b5ded-680b-4537-b2ea-35712ce992b5", "metadata": {}, "source": ["---\n", "## Evaluate The Model: In The Notebook (local runtime)"]}, {"cell_type": "markdown", "id": "42fc016d", "metadata": {}, "source": ["Evaluate the model with the test data:"]}, {"cell_type": "code", "execution_count": 33, "id": "84fc5083", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:29:21.556561: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:29:21.556616: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["286/286 [==============================] - 3s 7ms/step - loss: 0.0056 - accuracy: 0.9993 - auprc: 0.9994\n"]}], "source": ["loss, accuracy, auprc = model.evaluate(test)"]}, {"cell_type": "code", "execution_count": 34, "id": "4a655b7e-21e0-4a82-aac4-fa776d584485", "metadata": {}, "outputs": [], "source": ["expRun.log_metrics({'test_loss': loss, 'test_accuracy': accuracy, 'test_auprc': auprc})"]}, {"cell_type": "code", "execution_count": 35, "id": "61787273", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:29:24.625741: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:29:24.625795: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["283/283 [==============================] - 2s 7ms/step - loss: 0.0058 - accuracy: 0.9992 - auprc: 0.9995\n"]}], "source": ["loss, accuracy, auprc = model.evaluate(validate)"]}, {"cell_type": "code", "execution_count": 36, "id": "154f982b-8b2e-4aa0-af4d-62cc483cf168", "metadata": {}, "outputs": [], "source": ["expRun.log_metrics({'val_loss': loss, 'val_accuracy': accuracy, 'val_auprc': auprc})"]}, {"cell_type": "code", "execution_count": 37, "id": "190d870d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:29:27.306970: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:29:27.307036: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2281/2281 [==============================] - 29s 13ms/step - loss: 0.0061 - accuracy: 0.9993 - auprc: 0.9994\n"]}], "source": ["loss, accuracy, auprc = model.evaluate(train)"]}, {"cell_type": "code", "execution_count": 38, "id": "5bce3736-904b-481c-a9b9-3d1dde474ef2", "metadata": {}, "outputs": [], "source": ["expRun.log_metrics({'train_loss': loss, 'train_accuracy': accuracy, 'train_auprc': auprc})"]}, {"cell_type": "markdown", "id": "c5ab0b29-608a-4cf4-bf1f-d9ab801d8834", "metadata": {}, "source": ["---\n", "## Custom Evaluation\n", "\n", "Using the test data, calculate a series of metrics using [scikit-learn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html).  Using TFIO to read the batches from BigQuery means the first step is getting the predictions and actual values into numpy arrays:"]}, {"cell_type": "code", "execution_count": 39, "id": "1180dd37-ac7c-4d0f-8095-81793aa53009", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:29:56.816335: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:29:56.816393: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["286/286 [==============================] - 4s 7ms/step\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2023-09-28 23:30:00.223257: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-09-28 23:30:00.223323: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}], "source": ["predictions = model.predict(test)\n", "\n", "actuals = np.empty(shape = [0, predictions.shape[1]])\n", "for features, target in test.take(-1): # -1 indicates all batches\n", "    actuals = np.append(actuals, target.numpy(), axis = 0)\n", "\n", "predictions_proba = np.max(predictions, axis = 1)\n", "predictions = np.argmax(predictions, axis = 1)\n", "actuals = np.argmax(actuals, axis = 1)"]}, {"cell_type": "code", "execution_count": 40, "id": "68e489b0-b916-4548-80a0-6715969acee8", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["actuals[-20:]"]}, {"cell_type": "code", "execution_count": 41, "id": "29cbc551-6b4e-4930-bc8c-4b1fa056f990", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"]}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": ["predictions[-20:]"]}, {"cell_type": "markdown", "id": "90393bcd-ce91-41fb-be30-4618f469be36", "metadata": {}, "source": ["Calculate metrics:"]}, {"cell_type": "code", "execution_count": 42, "id": "9221ab09-d759-4d21-8620-a5d4486f24e8", "metadata": {}, "outputs": [{"data": {"text/plain": ["0.02655661782230954"]}, "execution_count": 42, "metadata": {}, "output_type": "execute_result"}], "source": ["metrics.log_loss(actuals, predictions)"]}, {"cell_type": "code", "execution_count": 43, "id": "bea81c35-23b9-4ff1-8bb9-988381f99260", "metadata": {}, "outputs": [{"data": {"text/plain": ["0.9992632095993264"]}, "execution_count": 43, "metadata": {}, "output_type": "execute_result"}], "source": ["metrics.accuracy_score(actuals, predictions)"]}, {"cell_type": "code", "execution_count": 44, "id": "4dd05d09-5cc2-4671-b485-c1ea55aa11b1", "metadata": {}, "outputs": [{"data": {"text/plain": ["0.5797465127493853"]}, "execution_count": 44, "metadata": {}, "output_type": "execute_result"}], "source": ["metrics.average_precision_score(actuals, predictions)"]}, {"cell_type": "markdown", "id": "77589af5-adeb-4ad0-a324-7d689936fa3c", "metadata": {}, "source": ["---\n", "## Evaluate The Training With Tensorboard (On Vertex AI Experiments)\n", "\n", "Resource: https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview"]}, {"cell_type": "code", "execution_count": 67, "id": "57584d53-bd3e-404a-a32e-4bda3dc75cef", "metadata": {}, "outputs": [], "source": ["#!pip install google-cloud-aiplatform[tensorboard] -U -q"]}, {"cell_type": "code", "execution_count": 66, "id": "7fe61a04-d057-430c-8cab-22ede95e842f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7876136041294331904+experiments+experiment-05-05-tf-classification-dnn\n", "\u001b[1m[2023-09-29T00:05:45]\u001b[0m Started scanning logdir.\n", "\u001b[1m[2023-09-29T00:05:47]\u001b[0m Total uploaded: 36 scalars, 48 tensors (17.2 kB), 1 binary objects (102.2 kB)\n", "One time TensorBoard log upload completed...\u001b[0m\n"]}], "source": ["aiplatform.upload_tb_log(\n", "    tensorboard_id = tb.name,\n", "    tensorboard_experiment_name = EXPERIMENT_NAME,\n", "    logdir = f'{DIR}/logs',\n", "    experiment_display_name = EXPERIMENT_NAME,\n", "    run_name_prefix = RUN_NAME,\n", "    description = EXPERIMENT_NAME\n", ")"]}, {"cell_type": "markdown", "id": "c8cc6b44-77b5-4acb-813b-ff332a907985", "metadata": {}, "source": ["---\n", "## Evaluate The Training With Tensorboard (Local to Notebook)\n", "\n", "Visual ML\n", "\n", "Resource: https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"]}, {"cell_type": "code", "execution_count": 45, "id": "87bd476f-ca49-442f-8524-b762a6b21714", "metadata": {}, "outputs": [], "source": ["%load_ext tensorboard"]}, {"cell_type": "code", "execution_count": null, "id": "562c6c6a-4b5e-44b4-aec0-64b449e36feb", "metadata": {}, "outputs": [], "source": ["%tensorboard --logdir $DIR/logs"]}, {"cell_type": "markdown", "id": "2913711d", "metadata": {}, "source": ["---\n", "## Save The Model"]}, {"cell_type": "markdown", "id": "cd961d36-64ba-43f3-a1e4-395a546846c6", "metadata": {}, "source": ["Create Prediction from a batch of the test data and review first row:"]}, {"cell_type": "code", "execution_count": 47, "id": "039c4884", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2023-03-27 12:01:48.976412: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n", "2023-03-27 12:01:48.976474: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["1/1 [==============================] - 2s 2s/step\n"]}, {"data": {"text/plain": ["array([0.99728376, 0.0027162 ], dtype=float32)"]}, "execution_count": 47, "metadata": {}, "output_type": "execute_result"}], "source": ["model.predict(test.take(1))[0]"]}, {"cell_type": "markdown", "id": "060db155", "metadata": {}, "source": ["Save The Model"]}, {"cell_type": "code", "execution_count": 48, "id": "81f63da1", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["WARNING:absl:Function `_wrapped_model` contains input name(s) Amount, Time, V1, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19, V2, V20, V21, V22, V23, V24, V25, V26, V27, V28, V3, V4, V5, V6, V7, V8, V9 with unsupported characters which will be renamed to amount, time, v1, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v2, v20, v21, v22, v23, v24, v25, v26, v27, v28, v3, v4, v5, v6, v7, v8, v9 in the SavedModel.\n", "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: gs://statmike-mlops-349915/05/05/models/20230327115749/model/assets\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: gs://statmike-mlops-349915/05/05/models/20230327115749/model/assets\n"]}], "source": ["model.save(f'{URI}/models/{TIMESTAMP}/model')"]}, {"cell_type": "code", "execution_count": 49, "id": "2c95f61d-8042-4f86-b85f-78fdd926f8c0", "metadata": {}, "outputs": [], "source": ["expRun.log_params({'model.save': f'{URI}/models/{TIMESTAMP}/model'})"]}, {"cell_type": "markdown", "id": "9f30c637-a8c4-47bf-ad9a-88ae6577d212", "metadata": {}, "source": ["### Review The Saved Model"]}, {"cell_type": "markdown", "id": "e4dcc6f5-cdcb-4973-accf-181859e54131", "metadata": {}, "source": ["#### Keras Model Load"]}, {"cell_type": "code", "execution_count": 50, "id": "7e6e5588-9e0e-4226-a67a-3423d8f43e46", "metadata": {}, "outputs": [], "source": ["keras_model = tf.keras.models.load_model(f'{URI}/models/{TIMESTAMP}/model')"]}, {"cell_type": "code", "execution_count": 51, "id": "e4575186-76d3-41da-8a65-94e6c0a2b22e", "metadata": {}, "outputs": [{"data": {"text/plain": ["'05'"]}, "execution_count": 51, "metadata": {}, "output_type": "execute_result"}], "source": ["keras_model.name"]}, {"cell_type": "code", "execution_count": 52, "id": "7d64c26b-29f6-4512-a042-6b5680f6106c", "metadata": {}, "outputs": [{"data": {"text/plain": ["[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Amount')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Time')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V1')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V10')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V11')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V12')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V13')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V14')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V15')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V16')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V17')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V18')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V19')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V2')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V20')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V21')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V22')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V23')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V24')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V25')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V26')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V27')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V28')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V3')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V4')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V5')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V6')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V7')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V8')>,\n", " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'V9')>]"]}, "execution_count": 52, "metadata": {}, "output_type": "execute_result"}], "source": ["keras_model.inputs"]}, {"cell_type": "code", "execution_count": 53, "id": "7a61a23a-67ab-4766-8ed0-3b28f1a00eda", "metadata": {}, "outputs": [{"data": {"text/plain": ["'logistic/Softmax:0'"]}, "execution_count": 53, "metadata": {}, "output_type": "execute_result"}], "source": ["keras_model.output.name"]}, {"cell_type": "code", "execution_count": 54, "id": "8781d622-bea9-477e-a684-eeaecb3c08f2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"05\"\n", "__________________________________________________________________________________________________\n", " Layer (type)                   Output Shape         Param #     Connected to                     \n", "==================================================================================================\n", " Amount (InputLayer)            [(None, 1)]          0           []                               \n", "                                                                                                  \n", " Time (InputLayer)              [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V1 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V10 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V11 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V12 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V13 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V14 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V15 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V16 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V17 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V18 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V19 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V2 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V20 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V21 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V22 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V23 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V24 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V25 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V26 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V27 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V28 (InputLayer)               [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V3 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V4 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V5 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V6 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V7 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V8 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " V9 (InputLayer)                [(None, 1)]          0           []                               \n", "                                                                                                  \n", " feature_layer (DenseFeatures)  (None, 30)           0           ['Amount[0][0]',                 \n", "                                                                  'Time[0][0]',                   \n", "                                                                  'V1[0][0]',                     \n", "                                                                  'V10[0][0]',                    \n", "                                                                  'V11[0][0]',                    \n", "                                                                  'V12[0][0]',                    \n", "                                                                  'V13[0][0]',                    \n", "                                                                  'V14[0][0]',                    \n", "                                                                  'V15[0][0]',                    \n", "                                                                  'V16[0][0]',                    \n", "                                                                  'V17[0][0]',                    \n", "                                                                  'V18[0][0]',                    \n", "                                                                  'V19[0][0]',                    \n", "                                                                  'V2[0][0]',                     \n", "                                                                  'V20[0][0]',                    \n", "                                                                  'V21[0][0]',                    \n", "                                                                  'V22[0][0]',                    \n", "                                                                  'V23[0][0]',                    \n", "                                                                  'V24[0][0]',                    \n", "                                                                  'V25[0][0]',                    \n", "                                                                  'V26[0][0]',                    \n", "                                                                  'V27[0][0]',                    \n", "                                                                  'V28[0][0]',                    \n", "                                                                  'V3[0][0]',                     \n", "                                                                  'V4[0][0]',                     \n", "                                                                  'V5[0][0]',                     \n", "                                                                  'V6[0][0]',                     \n", "                                                                  'V7[0][0]',                     \n", "                                                                  'V8[0][0]',                     \n", "                                                                  'V9[0][0]']                     \n", "                                                                                                  \n", " batch_normalization_layer (Bat  (None, 30)          120         ['feature_layer[0][0]']          \n", " chNormalization)                                                                                 \n", "                                                                                                  \n", " logistic (Dense)               (None, 2)            62          ['batch_normalization_layer[0][0]\n", "                                                                 ']                               \n", "                                                                                                  \n", "==================================================================================================\n", "Total params: 182\n", "Trainable params: 122\n", "Non-trainable params: 60\n", "__________________________________________________________________________________________________\n"]}], "source": ["keras_model.summary()"]}, {"cell_type": "markdown", "id": "892fd452-00a2-4b67-aeb7-f114353623c5", "metadata": {}, "source": ["#### TensorFlow Model Load"]}, {"cell_type": "code", "execution_count": 55, "id": "dbc41986-51e0-4358-a8d5-9793dd8f1519", "metadata": {}, "outputs": [], "source": ["tf_model = tf.saved_model.load(f'{URI}/models/{TIMESTAMP}/model')"]}, {"cell_type": "code", "execution_count": 56, "id": "d05bc0e6-5cd6-4dfa-8f7f-c4a6a119c2f2", "metadata": {}, "outputs": [{"data": {"text/plain": ["_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, V27, V11, V7, V5, V3, Time, V25, V21, V22, V15, Amount, V10, V4, V26, V17, V28, V6, V2, V16, V12, V24, V14, V9, V1, V13, V8, V19, V18, V20, V23) at 0x7F6F7849F090>})"]}, "execution_count": 56, "metadata": {}, "output_type": "execute_result"}], "source": ["tf_model.signatures"]}, {"cell_type": "code", "execution_count": 57, "id": "e7561b4b-cff3-422e-91f6-62b74ff42330", "metadata": {}, "outputs": [{"data": {"text/plain": ["<ConcreteFunction signature_wrapper(*, V27, V11, V7, V5, V3, Time, V25, V21, V22, V15, Amount, V10, V4, V26, V17, V28, V6, V2, V16, V12, V24, V14, V9, V1, V13, V8, V19, V18, V20, V23) at 0x7F6F7849F090>"]}, "execution_count": 57, "metadata": {}, "output_type": "execute_result"}], "source": ["tf_model.signatures['serving_default']"]}, {"cell_type": "code", "execution_count": 58, "id": "14cba705-7dd4-469f-b015-5dabb0436116", "metadata": {}, "outputs": [{"data": {"text/plain": ["dict_keys(['V27', 'V11', 'V7', 'V5', 'V3', 'Time', 'V25', 'V21', 'V22', 'V15', 'Amount', 'V10', 'V4', 'V26', 'V17', 'V28', 'V6', 'V2', 'V16', 'V12', 'V24', 'V14', 'V9', 'V1', 'V13', 'V8', 'V19', 'V18', 'V20', 'V23'])"]}, "execution_count": 58, "metadata": {}, "output_type": "execute_result"}], "source": ["tf_model.signatures['serving_default'].structured_input_signature[1].keys()"]}, {"cell_type": "code", "execution_count": 59, "id": "990d3424-951a-494d-91cd-5801f29ed0c3", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'logistic': TensorSpec(shape=(None, 2), dtype=tf.float32, name='logistic')}"]}, "execution_count": 59, "metadata": {}, "output_type": "execute_result"}], "source": ["tf_model.signatures['serving_default'].structured_outputs"]}, {"cell_type": "markdown", "id": "d7cd70f0-ae0c-4a14-b5df-3c71742f97cc", "metadata": {}, "source": ["#### TensorFlow SavedModel CLI\n", "\n", "To see the input and output specification for the TensorFlow model use the [SavedModel CLI](https://www.tensorflow.org/guide/saved_model#details_of_the_savedmodel_command_line_interface):"]}, {"cell_type": "code", "execution_count": null, "id": "a549ef5d-1d4c-4e8c-ba44-5dda57190479", "metadata": {}, "outputs": [], "source": ["# Inspect model inputs and outpus with SavedModel CLI\n", "!saved_model_cli show --dir {URI}/models/{TIMESTAMP}/model --all"]}, {"cell_type": "markdown", "id": "93461c88-9668-47bf-afec-cc2578b14670", "metadata": {}, "source": ["---\n", "## Model Explainability - Feature-Based Attributions\n", "\n", "This will bring the concepts of [05Tools - Explainability - Feature-Based.ipynb](./05Tools%20-%20Explainability%20-%20Feature-Based.ipynb) into the workflow."]}, {"cell_type": "code", "execution_count": null, "id": "86ba930c-3525-4a98-b1dd-7ab3d1715672", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "9d1d2efd-4f66-4daa-99f3-48cb14d0c0ad", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "ed0a86bd-97d7-4407-807d-7956887e2755", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "4dc74a2d-53a3-4bc5-9042-032b9a3d3076", "metadata": {}, "source": ["---\n", "## Serving"]}, {"cell_type": "markdown", "id": "10036d46", "metadata": {}, "source": ["### Vertex AI Model Registry - Add Model/Version\n", "\n", "Check to see if this model has been added to the Vertex AI Model Registry previously.  Add the current model as a a new model, or new version on an existing model."]}, {"cell_type": "code", "execution_count": 60, "id": "071c1f72", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model Already in Registry:\n", "Loading model as new default version.\n", "Creating Model\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:Creating Model\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05_05/operations/1395049152047480832\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05_05/operations/1395049152047480832\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Model created. Resource name: projects/1026793852137/locations/us-central1/models/model_05_05@13\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/1026793852137/locations/us-central1/models/model_05_05@13\n"]}, {"name": "stdout", "output_type": "stream", "text": ["To use this Model in another session:\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:To use this Model in another session:\n"]}, {"name": "stdout", "output_type": "stream", "text": ["model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/model_05_05@13')\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/model_05_05@13')\n"]}], "source": ["modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n", "\n", "upload_model = True\n", "if modelmatch:\n", "    print(\"Model Already in Registry:\")\n", "    if RUN_NAME in modelmatch[0].version_aliases:\n", "        print(\"This version already loaded, no action taken.\")\n", "        upload_model = False\n", "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n", "    else:\n", "        print('Loading model as new default version.')\n", "        parent_model = modelmatch[0].resource_name\n", "\n", "else:\n", "    print('This is a new model, creating in model registry')\n", "    parent_model = ''\n", "\n", "if upload_model:\n", "    model = aiplatform.Model.upload(\n", "        display_name = f'{SERIES}_{EXPERIMENT}',\n", "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n", "        parent_model =  parent_model,\n", "        serving_container_image_uri = DEPLOY_IMAGE,\n", "        artifact_uri = f\"{URI}/models/{TIMESTAMP}/model\",\n", "        is_default_version = True,\n", "        version_aliases = [RUN_NAME],\n", "        version_description = RUN_NAME,\n", "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}        \n", "    )"]}, {"cell_type": "markdown", "id": "3818d8eb-b15e-472f-90ff-b68cda9b4a2b", "metadata": {}, "source": [">**Note** on Version Aliases:\n", ">Expectation is a name starting with `a-z` that can include `[a-zA-Z0-9-]`\n", ">\n", ">**Retrieve a Model Resource**\n", ">[aiplatform.Model()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n", ">```Python\n", "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}') # retrieves default version\n", "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}@time-{TIMESTAMP}') # retrieves specific version\n", "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}', version = f'time-{TIMESTAMP}') # retrieves specific version\n", "```"]}, {"cell_type": "code", "execution_count": 61, "id": "b8b81f87-8a02-4bea-a105-c72366488f1e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Review the model in the Vertex AI Model Registry:\n", "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_05?project=statmike-mlops-349915\n"]}], "source": ["print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"]}, {"cell_type": "markdown", "id": "9239cefe-df02-4b6d-9433-8ab927ef191d", "metadata": {}, "source": ["### Add Custom Model Evaluation to The Model Registry\n", "\n", "The initial evauation of the model was done right after training.  Some of the metrics were written to Vertex AI Experiments above as part of this run.  This section will write evaluation metrics directly to the Model Registry to accompany this version of the trained model.\n", "\n", "**Resources:**\n", "- Doc: [Model Evaluation in Vertex AI](https://cloud.google.com/vertex-ai/docs/evaluation/introduction#tabular)\n", "- API: [aiplatform.gapic.ModelServiceClient.import_model_evaluation](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.model_service.ModelServiceClient#google_cloud_aiplatform_v1_services_model_service_ModelServiceClient_import_model_evaluation)\n", "- Example: [Get started with importing a custom model evaluation to the Vertex AI Model Registry](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_evaluation/get_started_with_custom_model_evaluation_import.ipynb)\n", "\n", "**Helpful Notes:**\n", "- Evaluations are loaded to a versioned model in the Vertex AI Model Registry.\n", "- Multiple evaluations can be loaded for the same model and version.\n", "- When loading an evaluation you must provide a schema file for the parameter `metrics_schema_uri`.\n", "- A complete list of these is provided by the Doc link above and can be directly reviewed at this [public GCS bucket](https://console.cloud.google.com/storage/browser/google-cloud-aiplatform/schema/modelevaluation).\n", "    - Make sure to use the `gsutil URI` in the API call."]}, {"cell_type": "markdown", "id": "05bc4bcd-81da-49e9-853e-e607d3918950", "metadata": {}, "source": ["Prepare metrics across a range of confidence thresholds:"]}, {"cell_type": "code", "execution_count": 333, "id": "e84042aa-1389-4b07-8a95-54eb0c58c63d", "metadata": {}, "outputs": [], "source": ["cm = []\n", "#for threshold in np.linspace(-0.005, 1.005, 202):\n", "for x in range(0, 203):\n", "    threshold = round(-0.005+x*0.005, 3)\n", "    preds = (predictions_proba < threshold).astype('float')\n", "    conmatrix = metrics.confusion_matrix(actuals, preds).astype(int)\n", "    FP = conmatrix.sum(axis = 0) - np.diag(conmatrix)\n", "    FP = FP[-1]\n", "    FN = conmatrix.sum(axis = 1) - np.diag(conmatrix)\n", "    FN = FN[-1]\n", "    TP = np.diag(conmatrix)\n", "    TP = TP[-1]\n", "    TN = conmatrix.sum() - (FP + FN + TP)\n", "    confidenceThreshold = threshold\n", "    if np.unique(preds).size < np.unique(actuals).size: precision = 0\n", "    else: precision = metrics.precision_score(actuals, preds)\n", "    recall = metrics.recall_score(actuals, preds)\n", "    \n", "    if precision > 0 or recall > 0:\n", "        if confidenceThreshold > 0 or confidenceThreshold < 0: current_threshold = {\"confidenceThreshold\": threshold}\n", "        else: current_threshold = {}\n", "        if precision > 0: current_threshold['precision'] = precision\n", "        if recall > 0: current_threshold['recall'] = recall\n", "        falsePositiveRate = FP / (FP + TN)\n", "        if falsePositiveRate > 0: current_threshold['falsePositiveRate'] = falsePositiveRate\n", "        f1Score = metrics.f1_score(actuals, preds)\n", "        if f1Score > 0: current_threshold['f1Score'] = f1score\n", "        truePositiveCount = TP\n", "        if truePositiveCount > 0: current_threshold['truePositiveCount'] = str(truePositiveCount)\n", "        falsePositiveCount = FP\n", "        if falsePositiveCount > 0: current_threshold['falsePositiveCount'] = str(falsePositiveCount)\n", "        trueNegativeCount = TN\n", "        if trueNegativeCount > 0: current_threshold['trueNegativeCount'] = str(trueNegativeCount)\n", "        falseNegativeCount = FN\n", "        if falseNegativeCount > 0: current_threshold['falseNegativeCount'] = str(falseNegativeCount)\n", "\n", "        current_threshold.update({\n", "            \"confusionMatrix\": {\n", "                \"annotationSpecs\": [{\"id\": \"0\", \"displayName\": '0'}, {\"id\": \"1\", \"displayName\": '1'}],\n", "                \"rows\": [{\"dataItemCounts\": row} for row in conmatrix.tolist()]\n", "            }\n", "        })\n", "        cm.append(current_threshold)"]}, {"cell_type": "code", "execution_count": 342, "id": "37f1c882-e9cd-408d-9c3e-955023e7b143", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'confidenceThreshold': 0.525,\n", " 'precision': 1.0,\n", " 'recall': 0.02127659574468085,\n", " 'f1Score': 0.0022698151198974922,\n", " 'truePositiveCount': '1',\n", " 'trueNegativeCount': '28455',\n", " 'falseNegativeCount': '46',\n", " 'confusionMatrix': {'annotationSpecs': [{'id': '0', 'displayName': '0'},\n", "   {'id': '1', 'displayName': '1'}],\n", "  'rows': [{'dataItemCounts': [28455, 0]}, {'dataItemCounts': [46, 1]}]}}"]}, "execution_count": 342, "metadata": {}, "output_type": "execute_result"}], "source": ["cm[0]"]}, {"cell_type": "markdown", "id": "2eb524d5-c9b4-4e35-9ee2-952fdcdc37d8", "metadata": {}, "source": ["Combine overall metrics with metrics across thresholds:"]}, {"cell_type": "code", "execution_count": 335, "id": "fb22b5ec-96e8-47f2-aa75-de9c00ceba51", "metadata": {}, "outputs": [], "source": ["model_metrics = {\n", "    \"auPrc\": metrics.average_precision_score(actuals, predictions),\n", "    \"auRoc\": metrics.roc_auc_score(actuals, predictions),\n", "    \"logLoss\": metrics.log_loss(actuals, predictions),\n", "    \"confidenceMetrics\": cm,\n", "    \"confusionMatrix\": {\n", "        \"annotationSpecs\": [{\"id\": \"0\", \"displayName\": '0'}, {\"id\": \"1\", \"displayName\": '1'}],\n", "        \"rows\": [{\"dataItemCounts\": row} for row in metrics.confusion_matrix(actuals, predictions).astype(int).tolist()]\n", "    }\n", "}"]}, {"cell_type": "markdown", "id": "eb46914f-d38f-43ef-9349-e8016a695d3d", "metadata": {}, "source": ["Setup the `aiplatform.gapic` (v1) aiplatform client:\n", "- more on [API versions](../Tips/aiplatform_notes.md)"]}, {"cell_type": "code", "execution_count": 344, "id": "aa0527a9-59e6-4c56-a5ae-fd623ba33cdb", "metadata": {}, "outputs": [], "source": ["model_client = aiplatform.gapic.ModelServiceClient(\n", "    client_options = {'api_endpoint': f\"{REGION}-aiplatform.googleapis.com\"}\n", ")"]}, {"cell_type": "code", "execution_count": 337, "id": "25dc7193-bbcf-49a7-b6f7-1241bf486562", "metadata": {}, "outputs": [], "source": ["eval_upload = model_client.import_model_evaluation(\n", "    parent = model.resource_name,\n", "    model_evaluation = aiplatform.gapic.ModelEvaluation(\n", "        display_name = 'custom_at_training',\n", "        metrics_schema_uri = 'gs://google-cloud-aiplatform/schema/modelevaluation/classification_metrics_1.0.0.yaml',\n", "        metrics = model_metrics\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": 340, "id": "7d10c1b4-8570-4a63-8714-2a09c232d31a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Review the evaluation in the Vertex AI Console:\n", "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_05/versions/13/evaluations/7910449600566253824?project=statmike-mlops-349915\n"]}], "source": ["print(f\"Review the evaluation in the Vertex AI Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}/versions/{model.version_id}/evaluations/{eval_upload.name.split('/')[-1]}?project={PROJECT_ID}\")"]}, {"cell_type": "markdown", "id": "c71483e3-3e22-4e81-9ac6-b99e85008f6f", "metadata": {}, "source": ["<p align=\"center\" width=\"100%\"><center><img src=\"../architectures/notebooks/05/05_eval.png\" width=\"75%\"></center></p>"]}, {"cell_type": "markdown", "id": "8402f4f5-38e3-4815-b588-86f0d748f9ce", "metadata": {}, "source": ["### Vertex AI Experiments - Update and Review"]}, {"cell_type": "code", "execution_count": null, "id": "5245e40a-ada2-4bfe-bff7-c6b6f4d96a6f", "metadata": {}, "outputs": [], "source": ["expRun.log_params({\n", "    'model.uri': model.uri,\n", "    'model.display_name': model.display_name,\n", "    'model.name': model.name,\n", "    'model.resource_name': model.resource_name,\n", "    'model.version_id': model.version_id,\n", "    'model.versioned_resource_name': model.versioned_resource_name\n", "})"]}, {"cell_type": "markdown", "id": "d5a78ce9-6860-4566-90fa-146f9df7f23e", "metadata": {}, "source": ["Complete the experiment run:"]}, {"cell_type": "code", "execution_count": 46, "id": "f4134d53-cea2-42da-a4d6-b6c71e835b4d", "metadata": {}, "outputs": [], "source": ["expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"]}, {"cell_type": "markdown", "id": "a9674c8d-0784-489c-a82e-353247cec0db", "metadata": {}, "source": ["Retrieve the experiment:"]}, {"cell_type": "code", "execution_count": 47, "id": "57b4e1d3-9836-4aac-9286-c0a07d4ccdf1", "metadata": {}, "outputs": [], "source": ["exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"]}, {"cell_type": "code", "execution_count": 48, "id": "f7e87042-6247-4177-8150-c2d07275415b", "metadata": {}, "outputs": [{"data": {"text/plain": ["'projects/1026793852137/locations/us-central1/tensorboards/7876136041294331904'"]}, "execution_count": 48, "metadata": {}, "output_type": "execute_result"}], "source": ["exp.backing_tensorboard_resource_name"]}, {"cell_type": "code", "execution_count": 49, "id": "65d603e1-b034-4469-a245-de9ab1334d28", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>experiment_name</th>\n", "      <th>run_name</th>\n", "      <th>run_type</th>\n", "      <th>state</th>\n", "      <th>param.training.prefetch</th>\n", "      <th>param.series</th>\n", "      <th>param.experiment</th>\n", "      <th>param.var_split</th>\n", "      <th>param.var_target</th>\n", "      <th>param.training.shuffle</th>\n", "      <th>...</th>\n", "      <th>metric.train_auprc</th>\n", "      <th>metric.test_loss</th>\n", "      <th>metric.val_accuracy</th>\n", "      <th>metric.val_auprc</th>\n", "      <th>time_series_metric.val_loss</th>\n", "      <th>time_series_metric.train_loss</th>\n", "      <th>time_series_metric.val_accuracy</th>\n", "      <th>time_series_metric.train_accuracy</th>\n", "      <th>time_series_metric.val_auprc</th>\n", "      <th>time_series_metric.train_auprc</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230928232537</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>COMPLETE</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999425</td>\n", "      <td>0.005639</td>\n", "      <td>0.999221</td>\n", "      <td>0.999511</td>\n", "      <td>0.005834</td>\n", "      <td>0.005466</td>\n", "      <td>0.999221</td>\n", "      <td>0.999224</td>\n", "      <td>0.999511</td>\n", "      <td>0.999526</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230928232224</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230928231922</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327115749</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999400</td>\n", "      <td>0.006905</td>\n", "      <td>0.999044</td>\n", "      <td>0.999323</td>\n", "      <td>0.007186</td>\n", "      <td>0.005903</td>\n", "      <td>0.999044</td>\n", "      <td>0.999180</td>\n", "      <td>0.999323</td>\n", "      <td>0.999393</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327111418</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>COMPLETE</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999399</td>\n", "      <td>0.005819</td>\n", "      <td>0.999079</td>\n", "      <td>0.999233</td>\n", "      <td>0.007015</td>\n", "      <td>0.006084</td>\n", "      <td>0.999079</td>\n", "      <td>0.999132</td>\n", "      <td>0.999233</td>\n", "      <td>0.999499</td>\n", "    </tr>\n", "    <tr>\n", "      <th>5</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327110946</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>6</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327105815</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>7</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327102042</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>8</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327095945</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>9</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327095258</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>10</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327094405</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>11</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327094201</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>12</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327094104</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>13</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327093948</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>14</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327093803</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>15</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327093643</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>NaN</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>...</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>16</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230325220538</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999538</td>\n", "      <td>0.005353</td>\n", "      <td>0.999327</td>\n", "      <td>0.999559</td>\n", "      <td>0.005339</td>\n", "      <td>0.005526</td>\n", "      <td>0.999327</td>\n", "      <td>0.999206</td>\n", "      <td>0.999559</td>\n", "      <td>0.999628</td>\n", "    </tr>\n", "    <tr>\n", "      <th>17</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230325135459</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999225</td>\n", "      <td>0.008844</td>\n", "      <td>0.998938</td>\n", "      <td>0.999075</td>\n", "      <td>0.010087</td>\n", "      <td>0.006562</td>\n", "      <td>0.998938</td>\n", "      <td>0.999084</td>\n", "      <td>0.999075</td>\n", "      <td>0.999429</td>\n", "    </tr>\n", "    <tr>\n", "      <th>18</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230324104933</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999353</td>\n", "      <td>0.006057</td>\n", "      <td>0.999256</td>\n", "      <td>0.999459</td>\n", "      <td>0.007014</td>\n", "      <td>0.006154</td>\n", "      <td>0.999256</td>\n", "      <td>0.999132</td>\n", "      <td>0.999459</td>\n", "      <td>0.999467</td>\n", "    </tr>\n", "    <tr>\n", "      <th>19</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230324103811</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>COMPLETE</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999300</td>\n", "      <td>0.008726</td>\n", "      <td>0.999221</td>\n", "      <td>0.999389</td>\n", "      <td>0.007320</td>\n", "      <td>0.006722</td>\n", "      <td>0.999221</td>\n", "      <td>0.999075</td>\n", "      <td>0.999389</td>\n", "      <td>0.999412</td>\n", "    </tr>\n", "    <tr>\n", "      <th>20</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230308225745</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>COMPLETE</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999562</td>\n", "      <td>0.005658</td>\n", "      <td>0.999186</td>\n", "      <td>0.999558</td>\n", "      <td>0.005796</td>\n", "      <td>0.004783</td>\n", "      <td>0.999186</td>\n", "      <td>0.999347</td>\n", "      <td>0.999558</td>\n", "      <td>0.999641</td>\n", "    </tr>\n", "    <tr>\n", "      <th>21</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230213133609</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>RUNNING</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999258</td>\n", "      <td>0.007538</td>\n", "      <td>0.998796</td>\n", "      <td>0.999196</td>\n", "      <td>0.008892</td>\n", "      <td>0.007255</td>\n", "      <td>0.998796</td>\n", "      <td>0.998939</td>\n", "      <td>0.999196</td>\n", "      <td>0.999404</td>\n", "    </tr>\n", "    <tr>\n", "      <th>22</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230210115433</td>\n", "      <td>system.ExperimentRun</td>\n", "      <td>COMPLETE</td>\n", "      <td>1.0</td>\n", "      <td>05</td>\n", "      <td>05</td>\n", "      <td>splits</td>\n", "      <td>Class</td>\n", "      <td>1000.0</td>\n", "      <td>...</td>\n", "      <td>0.999213</td>\n", "      <td>0.008543</td>\n", "      <td>0.998938</td>\n", "      <td>0.999210</td>\n", "      <td>0.008968</td>\n", "      <td>0.006154</td>\n", "      <td>0.998938</td>\n", "      <td>0.999176</td>\n", "      <td>0.999210</td>\n", "      <td>0.999425</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>23 rows \u00d7 37 columns</p>\n", "</div>"], "text/plain": ["                           experiment_name            run_name  \\\n", "0   experiment-05-05-tf-classification-dnn  run-20230928232537   \n", "1   experiment-05-05-tf-classification-dnn  run-20230928232224   \n", "2   experiment-05-05-tf-classification-dnn  run-20230928231922   \n", "3   experiment-05-05-tf-classification-dnn  run-20230327115749   \n", "4   experiment-05-05-tf-classification-dnn  run-20230327111418   \n", "5   experiment-05-05-tf-classification-dnn  run-20230327110946   \n", "6   experiment-05-05-tf-classification-dnn  run-20230327105815   \n", "7   experiment-05-05-tf-classification-dnn  run-20230327102042   \n", "8   experiment-05-05-tf-classification-dnn  run-20230327095945   \n", "9   experiment-05-05-tf-classification-dnn  run-20230327095258   \n", "10  experiment-05-05-tf-classification-dnn  run-20230327094405   \n", "11  experiment-05-05-tf-classification-dnn  run-20230327094201   \n", "12  experiment-05-05-tf-classification-dnn  run-20230327094104   \n", "13  experiment-05-05-tf-classification-dnn  run-20230327093948   \n", "14  experiment-05-05-tf-classification-dnn  run-20230327093803   \n", "15  experiment-05-05-tf-classification-dnn  run-20230327093643   \n", "16  experiment-05-05-tf-classification-dnn  run-20230325220538   \n", "17  experiment-05-05-tf-classification-dnn  run-20230325135459   \n", "18  experiment-05-05-tf-classification-dnn  run-20230324104933   \n", "19  experiment-05-05-tf-classification-dnn  run-20230324103811   \n", "20  experiment-05-05-tf-classification-dnn  run-20230308225745   \n", "21  experiment-05-05-tf-classification-dnn  run-20230213133609   \n", "22  experiment-05-05-tf-classification-dnn  run-20230210115433   \n", "\n", "                run_type     state  param.training.prefetch param.series  \\\n", "0   system.ExperimentRun  COMPLETE                      1.0           05   \n", "1   system.ExperimentRun   RUNNING                      NaN           05   \n", "2   system.ExperimentRun   RUNNING                      1.0           05   \n", "3   system.ExperimentRun   RUNNING                      1.0           05   \n", "4   system.ExperimentRun  COMPLETE                      1.0           05   \n", "5   system.ExperimentRun   RUNNING                      1.0           05   \n", "6   system.ExperimentRun   RUNNING                      NaN           05   \n", "7   system.ExperimentRun   RUNNING                      NaN           05   \n", "8   system.ExperimentRun   RUNNING                      NaN           05   \n", "9   system.ExperimentRun   RUNNING                      NaN           05   \n", "10  system.ExperimentRun   RUNNING                      NaN           05   \n", "11  system.ExperimentRun   RUNNING                      NaN           05   \n", "12  system.ExperimentRun   RUNNING                      NaN           05   \n", "13  system.ExperimentRun   RUNNING                      NaN           05   \n", "14  system.ExperimentRun   RUNNING                      NaN           05   \n", "15  system.ExperimentRun   RUNNING                      NaN           05   \n", "16  system.ExperimentRun   RUNNING                      1.0           05   \n", "17  system.ExperimentRun   RUNNING                      1.0           05   \n", "18  system.ExperimentRun   RUNNING                      1.0           05   \n", "19  system.ExperimentRun  COMPLETE                      1.0           05   \n", "20  system.ExperimentRun  COMPLETE                      1.0           05   \n", "21  system.ExperimentRun   RUNNING                      1.0           05   \n", "22  system.ExperimentRun  COMPLETE                      1.0           05   \n", "\n", "   param.experiment param.var_split param.var_target  param.training.shuffle  \\\n", "0                05          splits            Class                  1000.0   \n", "1                05          splits            Class                     NaN   \n", "2                05          splits            Class                  1000.0   \n", "3                05          splits            Class                  1000.0   \n", "4                05          splits            Class                  1000.0   \n", "5                05          splits            Class                  1000.0   \n", "6                05             NaN              NaN                     NaN   \n", "7                05             NaN              NaN                     NaN   \n", "8                05             NaN              NaN                     NaN   \n", "9                05             NaN              NaN                     NaN   \n", "10               05             NaN              NaN                     NaN   \n", "11               05             NaN              NaN                     NaN   \n", "12               05             NaN              NaN                     NaN   \n", "13               05             NaN              NaN                     NaN   \n", "14               05             NaN              NaN                     NaN   \n", "15               05             NaN              NaN                     NaN   \n", "16               05          splits            Class                  1000.0   \n", "17               05          splits            Class                  1000.0   \n", "18               05          splits            Class                  1000.0   \n", "19               05          splits            Class                  1000.0   \n", "20               05          splits            Class                  1000.0   \n", "21               05          splits            Class                  1000.0   \n", "22               05          splits            Class                  1000.0   \n", "\n", "    ...  metric.train_auprc  metric.test_loss metric.val_accuracy  \\\n", "0   ...            0.999425          0.005639            0.999221   \n", "1   ...                 NaN               NaN                 NaN   \n", "2   ...                 NaN               NaN                 NaN   \n", "3   ...            0.999400          0.006905            0.999044   \n", "4   ...            0.999399          0.005819            0.999079   \n", "5   ...                 NaN               NaN                 NaN   \n", "6   ...                 NaN               NaN                 NaN   \n", "7   ...                 NaN               NaN                 NaN   \n", "8   ...                 NaN               NaN                 NaN   \n", "9   ...                 NaN               NaN                 NaN   \n", "10  ...                 NaN               NaN                 NaN   \n", "11  ...                 NaN               NaN                 NaN   \n", "12  ...                 NaN               NaN                 NaN   \n", "13  ...                 NaN               NaN                 NaN   \n", "14  ...                 NaN               NaN                 NaN   \n", "15  ...                 NaN               NaN                 NaN   \n", "16  ...            0.999538          0.005353            0.999327   \n", "17  ...            0.999225          0.008844            0.998938   \n", "18  ...            0.999353          0.006057            0.999256   \n", "19  ...            0.999300          0.008726            0.999221   \n", "20  ...            0.999562          0.005658            0.999186   \n", "21  ...            0.999258          0.007538            0.998796   \n", "22  ...            0.999213          0.008543            0.998938   \n", "\n", "   metric.val_auprc  time_series_metric.val_loss  \\\n", "0          0.999511                     0.005834   \n", "1               NaN                          NaN   \n", "2               NaN                          NaN   \n", "3          0.999323                     0.007186   \n", "4          0.999233                     0.007015   \n", "5               NaN                          NaN   \n", "6               NaN                          NaN   \n", "7               NaN                          NaN   \n", "8               NaN                          NaN   \n", "9               NaN                          NaN   \n", "10              NaN                          NaN   \n", "11              NaN                          NaN   \n", "12              NaN                          NaN   \n", "13              NaN                          NaN   \n", "14              NaN                          NaN   \n", "15              NaN                          NaN   \n", "16         0.999559                     0.005339   \n", "17         0.999075                     0.010087   \n", "18         0.999459                     0.007014   \n", "19         0.999389                     0.007320   \n", "20         0.999558                     0.005796   \n", "21         0.999196                     0.008892   \n", "22         0.999210                     0.008968   \n", "\n", "   time_series_metric.train_loss time_series_metric.val_accuracy  \\\n", "0                       0.005466                        0.999221   \n", "1                            NaN                             NaN   \n", "2                            NaN                             NaN   \n", "3                       0.005903                        0.999044   \n", "4                       0.006084                        0.999079   \n", "5                            NaN                             NaN   \n", "6                            NaN                             NaN   \n", "7                            NaN                             NaN   \n", "8                            NaN                             NaN   \n", "9                            NaN                             NaN   \n", "10                           NaN                             NaN   \n", "11                           NaN                             NaN   \n", "12                           NaN                             NaN   \n", "13                           NaN                             NaN   \n", "14                           NaN                             NaN   \n", "15                           NaN                             NaN   \n", "16                      0.005526                        0.999327   \n", "17                      0.006562                        0.998938   \n", "18                      0.006154                        0.999256   \n", "19                      0.006722                        0.999221   \n", "20                      0.004783                        0.999186   \n", "21                      0.007255                        0.998796   \n", "22                      0.006154                        0.998938   \n", "\n", "   time_series_metric.train_accuracy time_series_metric.val_auprc  \\\n", "0                           0.999224                     0.999511   \n", "1                                NaN                          NaN   \n", "2                                NaN                          NaN   \n", "3                           0.999180                     0.999323   \n", "4                           0.999132                     0.999233   \n", "5                                NaN                          NaN   \n", "6                                NaN                          NaN   \n", "7                                NaN                          NaN   \n", "8                                NaN                          NaN   \n", "9                                NaN                          NaN   \n", "10                               NaN                          NaN   \n", "11                               NaN                          NaN   \n", "12                               NaN                          NaN   \n", "13                               NaN                          NaN   \n", "14                               NaN                          NaN   \n", "15                               NaN                          NaN   \n", "16                          0.999206                     0.999559   \n", "17                          0.999084                     0.999075   \n", "18                          0.999132                     0.999459   \n", "19                          0.999075                     0.999389   \n", "20                          0.999347                     0.999558   \n", "21                          0.998939                     0.999196   \n", "22                          0.999176                     0.999210   \n", "\n", "   time_series_metric.train_auprc  \n", "0                        0.999526  \n", "1                             NaN  \n", "2                             NaN  \n", "3                        0.999393  \n", "4                        0.999499  \n", "5                             NaN  \n", "6                             NaN  \n", "7                             NaN  \n", "8                             NaN  \n", "9                             NaN  \n", "10                            NaN  \n", "11                            NaN  \n", "12                            NaN  \n", "13                            NaN  \n", "14                            NaN  \n", "15                            NaN  \n", "16                       0.999628  \n", "17                       0.999429  \n", "18                       0.999467  \n", "19                       0.999412  \n", "20                       0.999641  \n", "21                       0.999404  \n", "22                       0.999425  \n", "\n", "[23 rows x 37 columns]"]}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": ["exp.get_data_frame()"]}, {"cell_type": "markdown", "id": "04072619-d95f-46ca-82e4-59302f1002f5", "metadata": {}, "source": ["Review the Experiments TensorBoard to compare runs:"]}, {"cell_type": "code", "execution_count": 67, "id": "3ce18389-8484-4d5d-a30e-c4841eb52e8f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The Experiment TensorBoard Link:\n", "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7876136041294331904+experiments+experiment-05-05-tf-classification-dnn\n"]}], "source": ["print(f\"The Experiment TensorBoard Link:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{exp.name}\")"]}, {"cell_type": "code", "execution_count": 68, "id": "37b9fded-da22-4c24-8d8c-54fefb07e1db", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>step</th>\n", "      <th>wall_time</th>\n", "      <th>train_accuracy</th>\n", "      <th>train_loss</th>\n", "      <th>train_auprc</th>\n", "      <th>val_auprc</th>\n", "      <th>val_loss</th>\n", "      <th>val_accuracy</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>1</td>\n", "      <td>2023-03-27 11:24:50.294000+00:00</td>\n", "      <td>0.998948</td>\n", "      <td>0.009058</td>\n", "      <td>0.999429</td>\n", "      <td>0.999212</td>\n", "      <td>0.008388</td>\n", "      <td>0.999079</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>2</td>\n", "      <td>2023-03-27 11:24:50.413000+00:00</td>\n", "      <td>0.999048</td>\n", "      <td>0.006842</td>\n", "      <td>0.999496</td>\n", "      <td>0.999215</td>\n", "      <td>0.007494</td>\n", "      <td>0.999079</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>3</td>\n", "      <td>2023-03-27 11:24:50.547000+00:00</td>\n", "      <td>0.999132</td>\n", "      <td>0.006084</td>\n", "      <td>0.999499</td>\n", "      <td>0.999233</td>\n", "      <td>0.007015</td>\n", "      <td>0.999079</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["   step                        wall_time  train_accuracy  train_loss  \\\n", "0     1 2023-03-27 11:24:50.294000+00:00        0.998948    0.009058   \n", "1     2 2023-03-27 11:24:50.413000+00:00        0.999048    0.006842   \n", "2     3 2023-03-27 11:24:50.547000+00:00        0.999132    0.006084   \n", "\n", "   train_auprc  val_auprc  val_loss  val_accuracy  \n", "0     0.999429   0.999212  0.008388      0.999079  \n", "1     0.999496   0.999215  0.007494      0.999079  \n", "2     0.999499   0.999233  0.007015      0.999079  "]}, "execution_count": 68, "metadata": {}, "output_type": "execute_result"}], "source": ["expRun.get_time_series_data_frame()"]}, {"cell_type": "markdown", "id": "ae09564a-2c89-47af-a1ec-380b74993f95", "metadata": {}, "source": ["### Review Experiment and Run in Console"]}, {"cell_type": "code", "execution_count": 69, "id": "05486974-79d0-4cb1-8947-3519868a3bd6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Review The Experiment in the Console:\n", "https://console.cloud.google.com/vertex-ai/locations/us-central1/experiments/experiment-05-05-tf-classification-dnn?project=statmike-mlops-349915\n"]}], "source": ["print(f'Review The Experiment in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}?project={PROJECT_ID}')"]}, {"cell_type": "code", "execution_count": 70, "id": "05ca25b9-94bf-4e63-b13e-7fcd11bee9bb", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Review The Experiment Run in the Console:\n", "https://console.cloud.google.com/vertex-ai/locations/us-central1/experiments/experiment-05-05-tf-classification-dnn/runs/experiment-05-05-tf-classification-dnn-run-20230327111418?project=statmike-mlops-349915\n"]}], "source": ["print(f'Review The Experiment Run in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}/runs/{EXPERIMENT_NAME}-{RUN_NAME}?project={PROJECT_ID}')"]}, {"cell_type": "markdown", "id": "76065eab-725c-43eb-b5b0-8f434cb1e5b9", "metadata": {}, "source": ["### Compare This Run Using Experiments"]}, {"cell_type": "markdown", "id": "ec8f20bd-badf-4744-a6ce-84d6e6d10af7", "metadata": {"tags": []}, "source": ["Get a list of all experiments in this project:"]}, {"cell_type": "code", "execution_count": 71, "id": "eed0de63-2a29-4b65-8ebb-63ee52bd58cd", "metadata": {}, "outputs": [], "source": ["experiments = aiplatform.Experiment.list()"]}, {"cell_type": "markdown", "id": "d77e6959-adef-4e68-8da5-b96a7cdb8e34", "metadata": {}, "source": ["Remove experiments not in the SERIES:"]}, {"cell_type": "code", "execution_count": 72, "id": "7e03bc04-1327-4cff-8704-c47438c5910f", "metadata": {}, "outputs": [], "source": ["experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"]}, {"cell_type": "markdown", "id": "7d3fdb86-60bb-428c-90c8-dcf3a0839bde", "metadata": {}, "source": ["Combine the runs from all experiments in SERIES into a single dataframe:"]}, {"cell_type": "code", "execution_count": 73, "id": "0b8c4d41-b572-4777-9169-2de273323c13", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["experiment-05-05f-tf-classification-dnn\n", "experiment-05-05i-tf-classification-dnn\n", "experiment-05-05h-tf-classification-dnn\n", "experiment-05-05g-tf-classification-dnn\n", "experiment-05-05e-tf-classification-dnn\n", "experiment-05-05d-tf-classification-dnn\n", "experiment-05-05c-tf-classification-dnn\n", "experiment-05-05b-tf-classification-dnn\n", "experiment-05-05a-tf-classification-dnn\n", "experiment-05-05-tf-classification-dnn\n"]}], "source": ["results = []\n", "for experiment in experiments:\n", "        results.append(experiment.get_data_frame())\n", "        print(experiment.name)\n", "results = pd.concat(results)"]}, {"cell_type": "markdown", "id": "ba01c508-7067-4a84-b978-c52fc543aa31", "metadata": {}, "source": ["Create ranks for models within experiment and across the entire SERIES:"]}, {"cell_type": "code", "execution_count": 74, "id": "91588c7a-5c9e-42e9-885d-ff1d38f88a7b", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>experiment_name</th>\n", "      <th>run_name</th>\n", "      <th>param.model.display_name</th>\n", "      <th>param.model.version_id</th>\n", "      <th>metric.test_auprc</th>\n", "      <th>series_rank</th>\n", "      <th>experiment_rank</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>80</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230210115433</td>\n", "      <td>05_05</td>\n", "      <td>6</td>\n", "      <td>0.999130</td>\n", "      <td>66.0</td>\n", "      <td>8.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>79</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230213133609</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999309</td>\n", "      <td>57.0</td>\n", "      <td>5.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>78</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230308225745</td>\n", "      <td>05_05</td>\n", "      <td>7</td>\n", "      <td>0.999469</td>\n", "      <td>42.0</td>\n", "      <td>2.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>77</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230324103811</td>\n", "      <td>05_05</td>\n", "      <td>8</td>\n", "      <td>0.999299</td>\n", "      <td>59.0</td>\n", "      <td>6.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>76</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230324104933</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999469</td>\n", "      <td>43.0</td>\n", "      <td>3.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>20</th>\n", "      <td>experiment-05-05i-tf-classification-dnn</td>\n", "      <td>run-20230211221928-5</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999584</td>\n", "      <td>9.0</td>\n", "      <td>7.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>19</th>\n", "      <td>experiment-05-05i-tf-classification-dnn</td>\n", "      <td>run-20230211221928-6</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999538</td>\n", "      <td>24.0</td>\n", "      <td>13.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>18</th>\n", "      <td>experiment-05-05i-tf-classification-dnn</td>\n", "      <td>run-20230211221928-7</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999538</td>\n", "      <td>25.0</td>\n", "      <td>14.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>17</th>\n", "      <td>experiment-05-05i-tf-classification-dnn</td>\n", "      <td>run-20230211221928-8</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999584</td>\n", "      <td>4.0</td>\n", "      <td>3.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>16</th>\n", "      <td>experiment-05-05i-tf-classification-dnn</td>\n", "      <td>run-20230211221928-9</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.999583</td>\n", "      <td>12.0</td>\n", "      <td>9.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>81 rows \u00d7 7 columns</p>\n", "</div>"], "text/plain": ["                            experiment_name              run_name  \\\n", "80   experiment-05-05-tf-classification-dnn    run-20230210115433   \n", "79   experiment-05-05-tf-classification-dnn    run-20230213133609   \n", "78   experiment-05-05-tf-classification-dnn    run-20230308225745   \n", "77   experiment-05-05-tf-classification-dnn    run-20230324103811   \n", "76   experiment-05-05-tf-classification-dnn    run-20230324104933   \n", "..                                      ...                   ...   \n", "20  experiment-05-05i-tf-classification-dnn  run-20230211221928-5   \n", "19  experiment-05-05i-tf-classification-dnn  run-20230211221928-6   \n", "18  experiment-05-05i-tf-classification-dnn  run-20230211221928-7   \n", "17  experiment-05-05i-tf-classification-dnn  run-20230211221928-8   \n", "16  experiment-05-05i-tf-classification-dnn  run-20230211221928-9   \n", "\n", "   param.model.display_name param.model.version_id  metric.test_auprc  \\\n", "80                    05_05                      6           0.999130   \n", "79                      NaN                    NaN           0.999309   \n", "78                    05_05                      7           0.999469   \n", "77                    05_05                      8           0.999299   \n", "76                      NaN                    NaN           0.999469   \n", "..                      ...                    ...                ...   \n", "20                      NaN                    NaN           0.999584   \n", "19                      NaN                    NaN           0.999538   \n", "18                      NaN                    NaN           0.999538   \n", "17                      NaN                    NaN           0.999584   \n", "16                      NaN                    NaN           0.999583   \n", "\n", "    series_rank  experiment_rank  \n", "80         66.0              8.0  \n", "79         57.0              5.0  \n", "78         42.0              2.0  \n", "77         59.0              6.0  \n", "76         43.0              3.0  \n", "..          ...              ...  \n", "20          9.0              7.0  \n", "19         24.0             13.0  \n", "18         25.0             14.0  \n", "17          4.0              3.0  \n", "16         12.0              9.0  \n", "\n", "[81 rows x 7 columns]"]}, "execution_count": 74, "metadata": {}, "output_type": "execute_result"}], "source": ["def ranker(metric = 'metric.test_auprc'):\n", "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n", "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n", "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n", "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n", "    \n", "ranks = ranker('metric.test_auprc')\n", "ranks"]}, {"cell_type": "code", "execution_count": 75, "id": "55d49220-2aef-4238-a8c4-18a83282cfe3", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>experiment_name</th>\n", "      <th>run_name</th>\n", "      <th>param.model.display_name</th>\n", "      <th>param.model.version_id</th>\n", "      <th>metric.test_auprc</th>\n", "      <th>series_rank</th>\n", "      <th>experiment_rank</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>62</th>\n", "      <td>experiment-05-05-tf-classification-dnn</td>\n", "      <td>run-20230327111418</td>\n", "      <td>05_05</td>\n", "      <td>12</td>\n", "      <td>0.999431</td>\n", "      <td>49.0</td>\n", "      <td>4.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                           experiment_name            run_name  \\\n", "62  experiment-05-05-tf-classification-dnn  run-20230327111418   \n", "\n", "   param.model.display_name param.model.version_id  metric.test_auprc  \\\n", "62                    05_05                     12           0.999431   \n", "\n", "    series_rank  experiment_rank  \n", "62         49.0              4.0  "]}, "execution_count": 75, "metadata": {}, "output_type": "execute_result"}], "source": ["current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n", "current_rank"]}, {"cell_type": "code", "execution_count": 76, "id": "93f1cd57-54c3-46b6-978a-f8c402c8c0ab", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The current model is ranked 4.0 within this experiment and 49.0 across this series.\n"]}], "source": ["print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"]}, {"cell_type": "markdown", "id": "dfd12b79", "metadata": {}, "source": ["### Vertex AI Prediction - Create/Retrieve The Endpoint For This Series"]}, {"cell_type": "code", "execution_count": 77, "id": "2cc28d98-b525-4385-9b95-489bf574f967", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/5876762107113897984\n", "Review the Endpoint in the Console:\n", "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/5876762107113897984?project=statmike-mlops-349915\n"]}], "source": ["endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n", "if endpoints:\n", "    endpoint = endpoints[0]\n", "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n", "else:\n", "    endpoint = aiplatform.Endpoint.create(\n", "        display_name = f\"{SERIES}\",\n", "        labels = {'series' : f\"{SERIES}\"}    \n", "    )\n", "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n", "    \n", "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"]}, {"cell_type": "code", "execution_count": 78, "id": "0a538bf0", "metadata": {}, "outputs": [{"data": {"text/plain": ["'05'"]}, "execution_count": 78, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.display_name"]}, {"cell_type": "code", "execution_count": 79, "id": "0a0029bd-9744-4449-91f0-56ef7ca5e535", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'6120070836201193472': 100}"]}, "execution_count": 79, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.traffic_split"]}, {"cell_type": "code", "execution_count": 93, "id": "85d06eba-82dc-4d50-8405-800d756e3584", "metadata": {}, "outputs": [], "source": ["deployed_models = endpoint.list_models()\n", "#deployed_models"]}, {"cell_type": "markdown", "id": "85ed7977-395d-4751-a09c-0c4c09d055e3", "metadata": {}, "source": ["#### Should This Model Be Deployed?\n", "Is it better than the model already deployed on the endpoint?"]}, {"cell_type": "code", "execution_count": 94, "id": "e5de9408-3148-4acc-b614-50cbcb4690ac", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["No models currently deployed.\n"]}], "source": ["deploy = False\n", "if deployed_models:\n", "    for deployed_model in deployed_models:\n", "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n", "        model_rank = current_rank['series_rank'].iloc[0]\n", "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n", "            print(f'The current model/version is already deployed.')\n", "            break\n", "        elif model_rank <= deployed_rank:\n", "            deploy = True\n", "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n", "            break\n", "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n", "else: \n", "    deploy = True\n", "    print('No models currently deployed.')"]}, {"cell_type": "markdown", "id": "25e49dd0", "metadata": {}, "source": ["#### Deploy Model To Endpoint"]}, {"cell_type": "code", "execution_count": 95, "id": "e739bc1c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Deploying model with 100% of traffic...\n", "Deploying Model projects/1026793852137/locations/us-central1/models/model_05_05 to Endpoint : projects/1026793852137/locations/us-central1/endpoints/5876762107113897984\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:Deploying Model projects/1026793852137/locations/us-central1/models/model_05_05 to Endpoint : projects/1026793852137/locations/us-central1/endpoints/5876762107113897984\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/5876762107113897984/operations/4239072316731949056\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/5876762107113897984/operations/4239072316731949056\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/5876762107113897984\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/5876762107113897984\n"]}], "source": ["if deploy:\n", "    print(f'Deploying model with 100% of traffic...')\n", "    endpoint.deploy(\n", "        model = model,\n", "        deployed_model_display_name = model.display_name,\n", "        traffic_percentage = 100,\n", "        machine_type = DEPLOY_COMPUTE,\n", "        min_replica_count = 1,\n", "        max_replica_count = 1\n", "    )\n", "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})')"]}, {"cell_type": "markdown", "id": "e758bde2-e521-4570-a5c7-44a1bda0eac0", "metadata": {}, "source": ["#### Remove Deployed Models without Traffic"]}, {"cell_type": "code", "execution_count": 96, "id": "00aa9466-6d9a-41cf-9bfa-7e8997572583", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model 05_05 with version 12 has traffic = 100\n"]}], "source": ["for deployed_model in endpoint.list_models():\n", "    if deployed_model.id in endpoint.traffic_split:\n", "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n", "    else:\n", "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n", "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"]}, {"cell_type": "code", "execution_count": 97, "id": "bacf24f6-c02e-409a-82b4-13c6e4a17dd1", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'7857939123854639104': 100}"]}, "execution_count": 97, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.traffic_split"]}, {"cell_type": "code", "execution_count": 98, "id": "7e416491-c909-45d3-8c79-a74dcafaa4f9", "metadata": {}, "outputs": [], "source": ["#endpoint.list_models()"]}, {"cell_type": "markdown", "id": "a58790ad", "metadata": {}, "source": ["---\n", "## Online Prediction\n", "\n", "See many more details on requesting predictions in the [05Tools - Prediction](./05Tools%20-%20Prediction.ipynb) notebook."]}, {"cell_type": "markdown", "id": "342a01eb", "metadata": {}, "source": ["### Prepare a record for prediction: instance and parameters lists"]}, {"cell_type": "code", "execution_count": 99, "id": "68911df0-5bee-44fb-9bb8-5aa363ae1c9d", "metadata": {}, "outputs": [], "source": ["n = 10\n", "pred = bq.query(\n", "    query = f\"\"\"\n", "        SELECT * EXCEPT({VAR_TARGET}, {VAR_OMIT}, splits)\n", "        FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\n", "        WHERE splits='TEST'\n", "        LIMIT {n}\n", "        \"\"\"\n", ").to_dataframe()"]}, {"cell_type": "code", "execution_count": 100, "id": "e2bae334-4223-4680-a2d0-d350f6a7ef1d", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Time</th>\n", "      <th>V1</th>\n", "      <th>V2</th>\n", "      <th>V3</th>\n", "      <th>V4</th>\n", "      <th>V5</th>\n", "      <th>V6</th>\n", "      <th>V7</th>\n", "      <th>V8</th>\n", "      <th>V9</th>\n", "      <th>...</th>\n", "      <th>V20</th>\n", "      <th>V21</th>\n", "      <th>V22</th>\n", "      <th>V23</th>\n", "      <th>V24</th>\n", "      <th>V25</th>\n", "      <th>V26</th>\n", "      <th>V27</th>\n", "      <th>V28</th>\n", "      <th>Amount</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>35337</td>\n", "      <td>1.092844</td>\n", "      <td>-0.013230</td>\n", "      <td>1.359829</td>\n", "      <td>2.731537</td>\n", "      <td>-0.707357</td>\n", "      <td>0.873837</td>\n", "      <td>-0.796130</td>\n", "      <td>0.437707</td>\n", "      <td>0.396770</td>\n", "      <td>...</td>\n", "      <td>-0.240428</td>\n", "      <td>0.037603</td>\n", "      <td>0.380026</td>\n", "      <td>-0.167647</td>\n", "      <td>0.027557</td>\n", "      <td>0.592115</td>\n", "      <td>0.219695</td>\n", "      <td>0.036970</td>\n", "      <td>0.010984</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>60481</td>\n", "      <td>1.238973</td>\n", "      <td>0.035226</td>\n", "      <td>0.063003</td>\n", "      <td>0.641406</td>\n", "      <td>-0.260893</td>\n", "      <td>-0.580097</td>\n", "      <td>0.049938</td>\n", "      <td>-0.034733</td>\n", "      <td>0.405932</td>\n", "      <td>...</td>\n", "      <td>-0.265080</td>\n", "      <td>-0.060003</td>\n", "      <td>-0.053585</td>\n", "      <td>-0.057718</td>\n", "      <td>0.104983</td>\n", "      <td>0.537987</td>\n", "      <td>0.589563</td>\n", "      <td>-0.046207</td>\n", "      <td>-0.006212</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>139587</td>\n", "      <td>1.870539</td>\n", "      <td>0.211079</td>\n", "      <td>0.224457</td>\n", "      <td>3.889486</td>\n", "      <td>-0.380177</td>\n", "      <td>0.249799</td>\n", "      <td>-0.577133</td>\n", "      <td>0.179189</td>\n", "      <td>-0.120462</td>\n", "      <td>...</td>\n", "      <td>-0.374356</td>\n", "      <td>0.196006</td>\n", "      <td>0.656552</td>\n", "      <td>0.180776</td>\n", "      <td>-0.060226</td>\n", "      <td>-0.228979</td>\n", "      <td>0.080827</td>\n", "      <td>0.009868</td>\n", "      <td>-0.036997</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>162908</td>\n", "      <td>-3.368339</td>\n", "      <td>-1.980442</td>\n", "      <td>0.153645</td>\n", "      <td>-0.159795</td>\n", "      <td>3.847169</td>\n", "      <td>-3.516873</td>\n", "      <td>-1.209398</td>\n", "      <td>-0.292122</td>\n", "      <td>0.760543</td>\n", "      <td>...</td>\n", "      <td>-0.923275</td>\n", "      <td>-0.545992</td>\n", "      <td>-0.252324</td>\n", "      <td>-1.171627</td>\n", "      <td>0.214333</td>\n", "      <td>-0.159652</td>\n", "      <td>-0.060883</td>\n", "      <td>1.294977</td>\n", "      <td>0.120503</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>165236</td>\n", "      <td>2.180149</td>\n", "      <td>0.218732</td>\n", "      <td>-2.637726</td>\n", "      <td>0.348776</td>\n", "      <td>1.063546</td>\n", "      <td>-1.249197</td>\n", "      <td>0.942021</td>\n", "      <td>-0.547652</td>\n", "      <td>-0.087823</td>\n", "      <td>...</td>\n", "      <td>-0.250653</td>\n", "      <td>0.234502</td>\n", "      <td>0.825237</td>\n", "      <td>-0.176957</td>\n", "      <td>0.563779</td>\n", "      <td>0.730183</td>\n", "      <td>0.707494</td>\n", "      <td>-0.131066</td>\n", "      <td>-0.090428</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>5</th>\n", "      <td>62606</td>\n", "      <td>1.199408</td>\n", "      <td>0.352007</td>\n", "      <td>0.379645</td>\n", "      <td>1.372017</td>\n", "      <td>0.291347</td>\n", "      <td>0.524919</td>\n", "      <td>-0.117555</td>\n", "      <td>0.132907</td>\n", "      <td>-0.935169</td>\n", "      <td>...</td>\n", "      <td>-0.042979</td>\n", "      <td>-0.050291</td>\n", "      <td>-0.126609</td>\n", "      <td>-0.022218</td>\n", "      <td>-0.599026</td>\n", "      <td>0.258188</td>\n", "      <td>0.928721</td>\n", "      <td>-0.058988</td>\n", "      <td>-0.008856</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>6</th>\n", "      <td>90719</td>\n", "      <td>1.937447</td>\n", "      <td>0.337882</td>\n", "      <td>-0.000630</td>\n", "      <td>3.816486</td>\n", "      <td>0.276515</td>\n", "      <td>1.079842</td>\n", "      <td>-0.730626</td>\n", "      <td>0.197353</td>\n", "      <td>1.137566</td>\n", "      <td>...</td>\n", "      <td>-0.315667</td>\n", "      <td>-0.038376</td>\n", "      <td>0.208914</td>\n", "      <td>0.160189</td>\n", "      <td>-0.015145</td>\n", "      <td>-0.162678</td>\n", "      <td>-0.000843</td>\n", "      <td>-0.018178</td>\n", "      <td>-0.039339</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>7</th>\n", "      <td>113350</td>\n", "      <td>1.891900</td>\n", "      <td>0.401086</td>\n", "      <td>-0.119983</td>\n", "      <td>4.047500</td>\n", "      <td>0.049952</td>\n", "      <td>0.192793</td>\n", "      <td>-0.108512</td>\n", "      <td>-0.040400</td>\n", "      <td>-0.390391</td>\n", "      <td>...</td>\n", "      <td>-0.267639</td>\n", "      <td>0.094177</td>\n", "      <td>0.613712</td>\n", "      <td>0.070986</td>\n", "      <td>0.079543</td>\n", "      <td>0.135219</td>\n", "      <td>0.128961</td>\n", "      <td>0.003667</td>\n", "      <td>-0.045079</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>8</th>\n", "      <td>156499</td>\n", "      <td>0.060003</td>\n", "      <td>1.461355</td>\n", "      <td>0.378915</td>\n", "      <td>2.835455</td>\n", "      <td>1.626526</td>\n", "      <td>-0.164732</td>\n", "      <td>1.551858</td>\n", "      <td>-0.412927</td>\n", "      <td>-1.735264</td>\n", "      <td>...</td>\n", "      <td>-0.175275</td>\n", "      <td>0.042293</td>\n", "      <td>0.277536</td>\n", "      <td>-0.123379</td>\n", "      <td>1.081552</td>\n", "      <td>-0.053079</td>\n", "      <td>-0.149809</td>\n", "      <td>-0.314438</td>\n", "      <td>-0.216539</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>9</th>\n", "      <td>73902</td>\n", "      <td>-1.859260</td>\n", "      <td>2.158799</td>\n", "      <td>1.085671</td>\n", "      <td>2.615483</td>\n", "      <td>0.246660</td>\n", "      <td>2.133925</td>\n", "      <td>-1.569015</td>\n", "      <td>-2.612353</td>\n", "      <td>-1.312509</td>\n", "      <td>...</td>\n", "      <td>0.590142</td>\n", "      <td>-0.867178</td>\n", "      <td>-0.700479</td>\n", "      <td>0.231972</td>\n", "      <td>-1.374527</td>\n", "      <td>0.140285</td>\n", "      <td>0.128806</td>\n", "      <td>0.153606</td>\n", "      <td>0.092042</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>10 rows \u00d7 30 columns</p>\n", "</div>"], "text/plain": ["     Time        V1        V2        V3        V4        V5        V6  \\\n", "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n", "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n", "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n", "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n", "4  165236  2.180149  0.218732 -2.637726  0.348776  1.063546 -1.249197   \n", "5   62606  1.199408  0.352007  0.379645  1.372017  0.291347  0.524919   \n", "6   90719  1.937447  0.337882 -0.000630  3.816486  0.276515  1.079842   \n", "7  113350  1.891900  0.401086 -0.119983  4.047500  0.049952  0.192793   \n", "8  156499  0.060003  1.461355  0.378915  2.835455  1.626526 -0.164732   \n", "9   73902 -1.859260  2.158799  1.085671  2.615483  0.246660  2.133925   \n", "\n", "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n", "0 -0.796130  0.437707  0.396770  ... -0.240428  0.037603  0.380026 -0.167647   \n", "1  0.049938 -0.034733  0.405932  ... -0.265080 -0.060003 -0.053585 -0.057718   \n", "2 -0.577133  0.179189 -0.120462  ... -0.374356  0.196006  0.656552  0.180776   \n", "3 -1.209398 -0.292122  0.760543  ... -0.923275 -0.545992 -0.252324 -1.171627   \n", "4  0.942021 -0.547652 -0.087823  ... -0.250653  0.234502  0.825237 -0.176957   \n", "5 -0.117555  0.132907 -0.935169  ... -0.042979 -0.050291 -0.126609 -0.022218   \n", "6 -0.730626  0.197353  1.137566  ... -0.315667 -0.038376  0.208914  0.160189   \n", "7 -0.108512 -0.040400 -0.390391  ... -0.267639  0.094177  0.613712  0.070986   \n", "8  1.551858 -0.412927 -1.735264  ... -0.175275  0.042293  0.277536 -0.123379   \n", "9 -1.569015 -2.612353 -1.312509  ...  0.590142 -0.867178 -0.700479  0.231972   \n", "\n", "        V24       V25       V26       V27       V28  Amount  \n", "0  0.027557  0.592115  0.219695  0.036970  0.010984     0.0  \n", "1  0.104983  0.537987  0.589563 -0.046207 -0.006212     0.0  \n", "2 -0.060226 -0.228979  0.080827  0.009868 -0.036997     0.0  \n", "3  0.214333 -0.159652 -0.060883  1.294977  0.120503     0.0  \n", "4  0.563779  0.730183  0.707494 -0.131066 -0.090428     0.0  \n", "5 -0.599026  0.258188  0.928721 -0.058988 -0.008856     0.0  \n", "6 -0.015145 -0.162678 -0.000843 -0.018178 -0.039339     0.0  \n", "7  0.079543  0.135219  0.128961  0.003667 -0.045079     0.0  \n", "8  1.081552 -0.053079 -0.149809 -0.314438 -0.216539     0.0  \n", "9 -1.374527  0.140285  0.128806  0.153606  0.092042     0.0  \n", "\n", "[10 rows x 30 columns]"]}, "execution_count": 100, "metadata": {}, "output_type": "execute_result"}], "source": ["pred"]}, {"cell_type": "code", "execution_count": 101, "id": "5640e67a", "metadata": {}, "outputs": [], "source": ["newobs = pred.to_dict(orient = 'records')\n", "#newobs[0]"]}, {"cell_type": "code", "execution_count": 102, "id": "ce631c5e-b200-43c8-9577-b77f957bb63f", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'Time': 35337,\n", " 'V1': 1.0928441854981998,\n", " 'V2': -0.0132303486713432,\n", " 'V3': 1.35982868199426,\n", " 'V4': 2.7315370965921004,\n", " 'V5': -0.707357349219652,\n", " 'V6': 0.8738370029866129,\n", " 'V7': -0.7961301510622031,\n", " 'V8': 0.437706509544851,\n", " 'V9': 0.39676985012996396,\n", " 'V10': 0.587438102569443,\n", " 'V11': -0.14979756231827498,\n", " 'V12': 0.29514781622888103,\n", " 'V13': -1.30382621882143,\n", " 'V14': -0.31782283120234495,\n", " 'V15': -2.03673231037199,\n", " 'V16': 0.376090905274179,\n", " 'V17': -0.30040350116459497,\n", " 'V18': 0.433799615590844,\n", " 'V19': -0.145082264348681,\n", " 'V20': -0.240427548108996,\n", " 'V21': 0.0376030733329398,\n", " 'V22': 0.38002620963091405,\n", " 'V23': -0.16764742731151097,\n", " 'V24': 0.0275573495476881,\n", " 'V25': 0.59211469704354,\n", " 'V26': 0.219695164116351,\n", " 'V27': 0.0369695108704894,\n", " 'V28': 0.010984441006191,\n", " 'Amount': 0.0}"]}, "execution_count": 102, "metadata": {}, "output_type": "execute_result"}], "source": ["newobs[0]"]}, {"cell_type": "code", "execution_count": 103, "id": "617e1e9f", "metadata": {}, "outputs": [], "source": ["#instances = [json_format.ParseDict(newobs[0], Value())]"]}, {"cell_type": "markdown", "id": "81d5eff9", "metadata": {}, "source": ["### Get Predictions: Python Client"]}, {"cell_type": "code", "execution_count": 104, "id": "dec05c59-dc93-4a69-90bf-5f3f96f4d006", "metadata": {}, "outputs": [{"data": {"text/plain": ["Prediction(predictions=[[0.993294418, 0.00670557469]], deployed_model_id='7857939123854639104', model_version_id='12', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05_05', explanations=None)"]}, "execution_count": 104, "metadata": {}, "output_type": "execute_result"}], "source": ["prediction = endpoint.predict(instances = newobs[0:1])\n", "prediction"]}, {"cell_type": "code", "execution_count": 105, "id": "06cb59fe", "metadata": {}, "outputs": [{"data": {"text/plain": ["Prediction(predictions=[[0.993294418, 0.00670557469], [0.998874247, 0.00112578226], [0.996102333, 0.0038977135], [0.999988675, 1.13643564e-05], [0.999644279, 0.000355680444], [0.993244469, 0.0067555015], [0.9964059, 0.00359401572], [0.992631078, 0.00736896461], [0.996538043, 0.00346192438], [0.999423862, 0.00057616405]], deployed_model_id='7857939123854639104', model_version_id='12', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05_05', explanations=None)"]}, "execution_count": 105, "metadata": {}, "output_type": "execute_result"}], "source": ["prediction = endpoint.predict(instances = newobs)\n", "prediction"]}, {"cell_type": "code", "execution_count": 106, "id": "3b22b4cb", "metadata": {}, "outputs": [{"data": {"text/plain": ["[0.993294418, 0.00670557469]"]}, "execution_count": 106, "metadata": {}, "output_type": "execute_result"}], "source": ["prediction.predictions[0]"]}, {"cell_type": "code", "execution_count": 107, "id": "b64e3283", "metadata": {}, "outputs": [{"data": {"text/plain": ["0"]}, "execution_count": 107, "metadata": {}, "output_type": "execute_result"}], "source": ["np.argmax(prediction.predictions[0])"]}, {"cell_type": "markdown", "id": "8c2a8676", "metadata": {}, "source": ["### Get Predictions: REST"]}, {"cell_type": "code", "execution_count": 108, "id": "5f97f30c", "metadata": {}, "outputs": [], "source": ["with open(f'{DIR}/request.json','w') as file:\n", "    file.write(json.dumps({\"instances\": newobs[0:1]}))"]}, {"cell_type": "code", "execution_count": 109, "id": "362dd5c2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "  \"predictions\": [\n", "    [\n", "      0.993294418,\n", "      0.00670557469\n", "    ]\n", "  ],\n", "  \"deployedModelId\": \"7857939123854639104\",\n", "  \"model\": \"projects/1026793852137/locations/us-central1/models/model_05_05\",\n", "  \"modelDisplayName\": \"05_05\",\n", "  \"modelVersionId\": \"12\"\n", "}\n"]}], "source": ["!curl -X POST \\\n", "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n", "-H \"Content-Type: application/json; charset=utf-8\" \\\n", "-d @{DIR}/request.json \\\n", "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"]}, {"cell_type": "markdown", "id": "74bd7c47", "metadata": {}, "source": ["### Get Predictions: gcloud (CLI)"]}, {"cell_type": "code", "execution_count": 110, "id": "d1e56e39", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n", "[[0.993294418, 0.00670557469]]\n"]}], "source": ["!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"]}, {"cell_type": "markdown", "id": "ba500bf3-d4fa-46a7-934d-3a667da69a9f", "metadata": {}, "source": ["---\n", "## Batch Prediction\n", "\n", "This section will create a batch prediction job in Vertex AI Prediction.  For more details and workflows around batch predictions see the notebook: [05Tools - Prediction - Batch.ipynb](./05Tools%20-%20Prediction%20-%20Batch.ipynb)."]}, {"cell_type": "code", "execution_count": null, "id": "fe4e2abb-74df-4cd6-9a0c-d05dded1ec6a", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "3a97a977-19fc-48de-a3ab-11033769e723", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "dc30f471-eb06-42a0-8c19-76e8cb50b429", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "391f38ee-d801-4b86-a43d-99f44de722a2", "metadata": {}, "source": ["---\n", "## Vertex AI Pipelines\n", "\n", "The notebook above has done many steps of an MLOps workflow:\n", "- setup training data\n", "- train a model\n", "- evaluated a model\n", "- integrate with Vertex AI Experiments and managed Tensorboard\n", "- Register model to Vertex AI Model Registry with versioning and evaluations\n", "- Create Vertex AI Prediction Endpoint and conditionally deploy the current model\n", "- Create a Batch Predictions Job\n", "\n", "What if this all needed to be automated?  This is where Vertex AI Pipelines, a fully managed service for running Kubeflow Pipelines (KFP) puts the workflow into action."]}, {"cell_type": "markdown", "id": "4a485ae6", "metadata": {}, "source": ["---\n", "## Remove Resources\n", "see notebook \"99 - Cleanup\""]}, {"cell_type": "code", "execution_count": 1, "id": "3e647604-c381-4ecd-bba1-ebea7ce39eff", "metadata": {}, "outputs": [], "source": ["# remove endpoints"]}, {"cell_type": "code", "execution_count": 2, "id": "a94cdf95-2547-4f34-9d53-3e51d61954c1", "metadata": {}, "outputs": [], "source": ["# remove models"]}, {"cell_type": "code", "execution_count": 3, "id": "0bc87178-04bd-4f7b-aef7-29fb213107d1", "metadata": {}, "outputs": [], "source": ["# remove experiments"]}, {"cell_type": "code", "execution_count": 4, "id": "77713dcc-d45d-4616-8611-75907ec4753c", "metadata": {}, "outputs": [], "source": ["# remove training job"]}, {"cell_type": "code", "execution_count": 5, "id": "5e64d513-77fa-4676-9eee-d8787ebc9f56", "metadata": {}, "outputs": [], "source": ["# remove pipeline runs"]}, {"cell_type": "code", "execution_count": 6, "id": "9b8f6079-523d-470b-8a99-67c26955aab3", "metadata": {}, "outputs": [], "source": ["# remove GCS files"]}, {"cell_type": "code", "execution_count": null, "id": "b018d864-838d-4f90-9538-47bfa729ad1e", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "feaaea05-d41c-4f5f-84fd-060f5fa4d99f", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "d1ba1f9e-739d-457a-bca8-17256e998c4d", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "a1d9f00b-6054-41b7-9ccf-5cd0a065d440", "metadata": {}, "outputs": [], "source": []}], "metadata": {"environment": {"kernel": "python3", "name": "tf2-gpu.2-12.m110", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 5}