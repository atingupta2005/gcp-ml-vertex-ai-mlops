{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57568ace",
   "metadata": {},
   "source": [
    "\n",
    "# 02a - Vertex AI - AutoML in GCP Console (no code)\n",
    "\n",
    "Use Vertex AI from the GCP Console for a no-code approach building a custom model with AutoML and deploy it for predictions.\n",
    "\n",
    "### Prerequisites:\n",
    "-  01 - BigQuery - Table Data Source\n",
    "\n",
    "### Resources:\n",
    "-  [AutoML Tabular Training Job With GCP Console](https://cloud.google.com/vertex-ai/docs/training/automl-console#tabular)\n",
    "\n",
    "### Related Training:\n",
    "-  [Tutorial for AutoML Tabular](https://cloud.google.com/vertex-ai/docs/tutorials/tabular-automl)\n",
    "\n",
    "### Conceptual Flow & Workflow\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/02a_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/02a_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e431d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Dataset (link to BigQuery table)\n",
    "\n",
    "From the Console:\n",
    "- Go to Vertex AI\n",
    "- Selected `Datasets`\n",
    "- Select `CREATE DATASET`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/ds_1.png\" width=\"50%\">\n",
    "\n",
    "- Name the dataset `02a`\n",
    "- Select `Tabular` and `Regression/classification`\n",
    "    - [More on Model Types](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)\n",
    "- Click `Create`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/ds_2.png\" width=\"50%\">\n",
    "\n",
    "- Under Select a data source pick `Select a table or view from BigQuery`\n",
    "- Enter the BigQuery path (or browse) to the prepped table created in notebook 01\n",
    "- Click `CONTINUE`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/ds_3.png\" width=\"50%\">\n",
    "\n",
    "- The `ANALYZE` tab for the dataset will be displayed for review:\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/ds_4.png\" width=\"50%\">\n",
    "\n",
    "- Going back to the `Datasets` dashboard will display the registered dataset\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/ds_5.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87433be1",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Model with AutoML\n",
    "\n",
    "On The Vertex AI console, select `Training`:\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/train_1.png\" width=\"50%\">\n",
    "\n",
    "Next to `Training` (near the top), select `CREATE`\n",
    "- For Dataset enter `02a`\n",
    "- For Objective make sure `Classification` is selected\n",
    "- Use `AutoML` for the method\n",
    "- Click `CONTINUE`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/train_2.png\" width=\"50%\">\n",
    "\n",
    "For `Model Details`:\n",
    "- Keep the default `Model name` which appends a datetime to the end of the dataset name\n",
    "- For `Target column` select the column to train predictions for\n",
    "- Expand `ADVANCED OPTIONS`:\n",
    "    - Select `Manual` for the Data split method\n",
    "    - Select the `splits` variables that was created in Notebook 01\n",
    "- Click `CONTINUE`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/train_3.png\" width=\"50%\">\n",
    "\n",
    "For `Training options`:\n",
    "- Click the `-` symbol next to any rows for variables that should be excluded from training, like the `transaction_id`\n",
    "- More on Adavanced Options:\n",
    "    - [Model Weights](https://cloud.google.com/vertex-ai/docs/datasets/prepare-tabular#weight)\n",
    "    - [Optimization Objectives](https://cloud.google.com/vertex-ai/docs/training/tabular-opt-obj)\n",
    "        - Pick AUC PR (Due to imbalance in Class)\n",
    "- Click `CONTINUE`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/train_4.png\" width=\"50%\">\n",
    "\n",
    "For `Compute and pricing`:\n",
    "- Enter a `Budget` of 1 node hour\n",
    "    - A guide for choosing the right amount of time can be found [here](https://cloud.google.com/vertex-ai/docs/training/automl-console#tabular): \n",
    "- Make sure `Enable early stopping` is toggled on\n",
    "- Click `START TRAINING`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/train_5.png\" width=\"50%\">\n",
    "\n",
    "Return to the Vertex AI console `Training` Menu:\n",
    "- Once the model completes training the name will be accompanied by a green check mark\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/train_6.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a962bf5",
   "metadata": {},
   "source": [
    "---\n",
    "## Model: Evaluate, Select, Deploy\n",
    "\n",
    "On the Vertex AI console, select `Models`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/model_1.png\" width=\"50%\">\n",
    "\n",
    "Select the model that was just trained - starts with `02a`:\n",
    "- This brings up the `EVALUATE` tab for the model\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/model_2.png\" width=\"50%\">\n",
    "\n",
    "Select the tab labeled `DEPLOY & TEST`:\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/model_3.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28bd96",
   "metadata": {},
   "source": [
    "---\n",
    "## Endpoint\n",
    "\n",
    "While still on the Vetex AI `Models` section with the `DEPLOY & TEST` tab selected:\n",
    "- select `DEPLOY TO ENDPOINT`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/model_3.png\" width=\"50%\">\n",
    "\n",
    "In the `Deploy to endpoint` menus, complete `Define your endpoint`:\n",
    "- For Endpoint name use `02a`\n",
    "- keep defaults for location and Access\n",
    "- Select `CONTINUE`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/endpoint_1.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db819d7a-0181-463a-99f1-fe72fbf5144a",
   "metadata": {},
   "source": [
    "In the `Model settings` section:\n",
    "- Traffic split should be 100\n",
    "- minimum number of computes nodes is 1\n",
    "- keep the remaining default values for max nodes, scaling, logging and explainability\n",
    "- Select `CONTINUE`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3f6b6-2784-49d1-a972-28137b81c07d",
   "metadata": {},
   "source": [
    "<img src=\"../architectures/notebooks/02a_screenshots/endpoint_2.png\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ae957-fd94-4f34-b167-9a52e26db02d",
   "metadata": {},
   "source": [
    "In the `Model monitoring` section:\n",
    "- Toggle `Enable model monitoring for this endpoint` on\n",
    "    - for monitoring job use the name `02a`\n",
    "    - use defaults for the other menue items\n",
    "- Select `CONTINUE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8960fa6-5cfd-441b-9cdc-aaff5cb006e7",
   "metadata": {},
   "source": [
    "<img src=\"../architectures/notebooks/02a_screenshots/endpoint_3.png\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1623e7c-14a1-408d-b266-f67de6dd4119",
   "metadata": {},
   "source": [
    "In the `Monitoring objectives` section:\n",
    "- Select `Prediction Drift Detection` under Monitoring objective\n",
    "- Select `DEPLOY`\n",
    "e..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0af22d-febe-43fe-8a83-b866d44c3e2a",
   "metadata": {},
   "source": [
    "<img src=\"../architectures/notebooks/02a_screenshots/endpoint_4.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd0c7a-b30c-462a-92dd-34ed3685f090",
   "metadata": {},
   "source": [
    "- Training-serving skew occurs when the feature data distribution in production deviates from the feature data distribution used to train the model. If the original training data is available, you can enable skew detection to monitor your models for training-serving skew.\n",
    "- Prediction drift occurs when feature data distribution in production changes significantly over time. If the original training data isn't available, you can enable drift detection to monitor the input data for changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7764095-e0a4-4b02-8c65-2498060c7e35",
   "metadata": {},
   "source": [
    "Once the model is done being deployed to the endpoint, click the `Endpoints` section of Vertex AI:\n",
    "- Select the endpoint that starts with `02a`\n",
    "- Review the endpoint dashboard for the deployed model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b69f48-b023-43b4-acad-39dd2c472645",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/endpoint_5.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4066f242",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch\n",
    "\n",
    "In the Verex AI console select the `Batch predictions` section:\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/batch_1.png\" width=\"50%\">\n",
    "\n",
    "Select `Create`:\n",
    "- name the prediction `02a`\n",
    "- for model name select the model that starts with `02a`\n",
    "- for Select source, pick BigQuery table\n",
    "- provide the location of the BigQuery source table\n",
    "- for storage location pick output format of BigQuery\n",
    "- provide the project for output in BigQuery\n",
    "- select `Generate feature importance`\n",
    "- select `Enable feature attributions for this model`\n",
    "- select `CREATE`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/batch_2.png\" width=\"50%\">\n",
    "\n",
    "Once the batch prediction job completes it will be listed with a green checkmark under `Batch Predictions`\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/batch_3.png\" width=\"50%\">\n",
    "\n",
    "Selecting the batch prediction job that starts with `02a` bring up the details of the prediction job\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/batch_4.png\" width=\"50%\">\n",
    "\n",
    "Select the linked BigQuery output table next to `Export location`:\n",
    "\n",
    "<img src=\"../architectures/notebooks/02a_screenshots/batch_5.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a23c17",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e6c09",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1e84b-8051-4c36-a99a-77703ec42f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ee41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '02a'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e4abd",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34f1cc",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e140b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50990d52",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ea95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d88337",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d83e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48165db",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3de847",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigquery.query(query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21148cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b438694",
   "metadata": {},
   "source": [
    "Need to understand the format of variables that the predictions expect.  AutoML may convert the type of some variables. The following cells retrieve the model from the endpoint and its schemata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob['Time'] = str(newob['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89923ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]\n",
    "parameters = json_format.ParseDict({}, Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671a9a5",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f0a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.list(filter=f'display_name={NOTEBOOK}')[0]\n",
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances=instances, parameters=parameters)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e716973",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predictions[0]['classes'][np.argmax(prediction.predictions[0]['scores'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c157f2",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b310ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd36ef",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4befbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030bbd84",
   "metadata": {},
   "source": [
    "---\n",
    "## Explanations\n",
    "Interpretation Guide\n",
    "- https://cloud.google.com/vertex-ai/docs/predictions/interpreting-results-automl#tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81348d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = endpoint.explain(instances=instances, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e142ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33621b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"attribution:\")\n",
    "print(\"baseline output\",explanation.explanations[0].attributions[0].baseline_output_value)\n",
    "print(\"instance output\",explanation.explanations[0].attributions[0].instance_output_value)\n",
    "print(\"output_index\",explanation.explanations[0].attributions[0].output_index)\n",
    "print(\"output display value\",explanation.explanations[0].attributions[0].output_display_name)\n",
    "print(\"approximation error\",explanation.explanations[0].attributions[0].approximation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d220f-0174-481a-a206-c7a6819015f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "features = []\n",
    "scores = []\n",
    "for k in explanation.explanations[0].attributions[0].feature_attributions:\n",
    "    features.append(k)\n",
    "    scores.append(explanation.explanations[0].attributions[0].feature_attributions[k])\n",
    "features = [x for _, x in sorted(zip(scores, features))]\n",
    "scores = sorted(scores)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9, 9)\n",
    "ax.barh(features, scores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb07f70",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
