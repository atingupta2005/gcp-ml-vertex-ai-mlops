{"cells": [{"cell_type": "markdown", "id": "13089ccd-0c6d-43b5-bee1-5d408eef82b0", "metadata": {}, "source": ["\n", "# Private Endpoints\n", "\n", "[Vertex AI Endpoints](https://cloud.google.com/vertex-ai/docs/general/deployment) are scalable resources for online hosting of models.  Models registered in Vertex AI Model Registry can be deployed to an endpoint.  Endpoints are configured by location and deployed models are configurable and with a wide variety of [compute configurations](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute) (machine types and GPUs).  When deploying a model to an endpoint the base level environment is configured with `minReplicaCount` and scaling is configured by choosing a larger value for `maxReplicaCount` to trigger [scaling behavior](https://cloud.google.com/vertex-ai/docs/general/deployment#scaling).\n", "\n", "Standard or Private?  Vertex AI offeres both standard and private endpoints.  This is more a statement of the exposure of the endpoint, both require authentication with a user/service that has appropriate IAM permissions.  [Private endpoints](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints) directly peer a project to the Vertex AI Prediction service hosting the underlying VMs which eliminates additional hops in network traffic and allows using efficient gRPC protocol = lower latency!  With either type of endpoint you can also use [customer-managed encryption keys with endpoints](https://cloud.google.com/vertex-ai/docs/general/cmek#resource-list) to encrypt model files used on the VMs.\n", "\n", "The [Vertex AI API](../Tips/aiplatform_notes.md) can be used to request predictions from any Vertex AI endpoint.  The user or [service](https://cloud.google.com/vertex-ai/docs/general/access-control#about_service_accounts_and_service_agents) that is authenticating and requesting the prediction will need the appropriate [IAM roles/permissions](https://cloud.google.com/vertex-ai/docs/general/access-control) to make this request - note the permission `aiplatform.endpoint.predict`.\n", "\n", "The choice of a private endpoint has several considerations:\n", "- Standard endpoints have traffic splits for hosting multiple models.  Private endpoints do not have traffic splitting.  To accomplish traffic splitting with private endpoints use multiple private endpoints and split traffic between them.\n", "- Standard endpoints have a [1.5Mb limit for prediction request]((https://cloud.google.com/vertex-ai/docs/general/deployment)) while private endpoints do not have this limit.\n", "- Additional [differences for private endpoints](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints#limitations)\n", "\n", "\n", "**Prerequisites:**\n", "- This notebook uses the model trained and registered by notebook [05a - Vertex AI Custom Model - TensorFlow - Custom Job With Python File.ipynb](../05%20-%20TensorFlow/05a%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Custom%20Job%20With%20Python%20File.ipynb)"]}, {"cell_type": "markdown", "id": "438260f1-db7d-4f3a-a155-c8921b17be65", "metadata": {}, "source": ["---\n", "## Setup"]}, {"cell_type": "markdown", "id": "ff43a125-cae1-4a50-afec-949b852202e3", "metadata": {}, "source": ["inputs:"]}, {"cell_type": "code", "execution_count": 5, "id": "2cfbbe54-8eae-44c5-9ba8-2e8c6ba6666f", "metadata": {}, "outputs": [{"data": {"text/plain": ["'statmike-mlops-349915'"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["project = !gcloud config get-value project\n", "PROJECT_ID = project[0]\n", "PROJECT_ID"]}, {"cell_type": "code", "execution_count": 46, "id": "f7574862-624f-4c5d-a0af-a4ccef17d530", "metadata": {}, "outputs": [], "source": ["REGION = 'us-central1'\n", "SERIES = 'dev'\n", "\n", "# source data\n", "BQ_PROJECT = PROJECT_ID\n", "BQ_DATASET = 'fraud'\n", "BQ_TABLE = 'fraud_prepped'\n", "\n", "# Resources\n", "DEPLOY_COMPUTE = 'n1-standard-4'\n", "\n", "# Model Training\n", "VAR_TARGET = 'Class'\n", "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"]}, {"cell_type": "markdown", "id": "9c29c783-957d-4d59-8f8c-1845ae6ea0c7", "metadata": {}, "source": ["packages:"]}, {"cell_type": "code", "execution_count": 15, "id": "2f0a1cd9-e520-4600-9765-33a3b7e2e17d", "metadata": {}, "outputs": [], "source": ["from google.cloud import aiplatform\n", "from google.cloud import bigquery"]}, {"cell_type": "markdown", "id": "6a9945df-925a-4fc9-a945-b8f3adf1a8ef", "metadata": {}, "source": ["clients:"]}, {"cell_type": "code", "execution_count": 16, "id": "c48de085-21af-4585-9349-185bcd30f83b", "metadata": {}, "outputs": [], "source": ["aiplatform.init(project = PROJECT_ID, location = REGION)\n", "bq = bigquery.Client(project = PROJECT_ID)"]}, {"cell_type": "markdown", "id": "47ec6c96-3552-4417-81b1-edc0edfb2262", "metadata": {}, "source": ["Enable APIs (if not already) for: \n", "- Service Networking (needed for createing compute addresses)\n", "- DNS (needed for deployment of model to endpoint"]}, {"cell_type": "code", "execution_count": 35, "id": "22ce620f-c673-4e6b-9fc2-f5f888351345", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Operation \"operations/acat.p2-1026793852137-862c3e2c-14c2-4a46-a053-d405df4d3291\" finished successfully.\n"]}], "source": ["!gcloud services enable servicenetworking.googleapis.com\n", "!gcloud services enable dns.googleapis.com"]}, {"cell_type": "markdown", "id": "1cdaa1a1-8d13-428b-b4eb-f1f27c7a3f9d", "metadata": {}, "source": ["---\n", "## Data Sample For Prediction Request"]}, {"cell_type": "code", "execution_count": 47, "id": "3af5e5ba-e3a4-4955-8f88-0bb22d6925ca", "metadata": {}, "outputs": [], "source": ["n = 10\n", "pred = bq.query(\n", "    query = f\"\"\"\n", "        SELECT * EXCEPT({VAR_TARGET}, {VAR_OMIT}, splits)\n", "        FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\n", "        WHERE splits='TEST'\n", "        LIMIT {n}\n", "        \"\"\"\n", ").to_dataframe()"]}, {"cell_type": "code", "execution_count": 48, "id": "837ac9ae-7a46-44ef-9d22-02aa6db25766", "metadata": {}, "outputs": [], "source": ["newobs = pred.to_dict(orient = 'records')"]}, {"cell_type": "markdown", "id": "1242bc8d-eada-485b-8a8a-435835261216", "metadata": {}, "source": ["---\n", "## Setup VPC Network Peering For Private Endpoints\n", "\n", "[Setting up VPC network peering](https://cloud.google.com/vertex-ai/docs/general/vpc-peering) for  the network named `default`to Vertex AI."]}, {"cell_type": "code", "execution_count": 1, "id": "aaad8bc0-7ee7-4422-9fbc-c77e1ca33a38", "metadata": {}, "outputs": [], "source": ["NETWORK_NAME = 'default'"]}, {"cell_type": "markdown", "id": "43233345-8298-4c83-82d8-2f5ad0289851", "metadata": {}, "source": ["List peering connections:"]}, {"cell_type": "code", "execution_count": 3, "id": "bb72d0c5-e3ad-4af5-b38b-abf1bdbb075f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Listed 0 items.\n"]}], "source": ["!gcloud compute networks peerings list --network $NETWORK_NAME"]}, {"cell_type": "markdown", "id": "932c8490-c4e3-40fc-afba-be8e245ce816", "metadata": {}, "source": ["Set a reserved range:"]}, {"cell_type": "code", "execution_count": 4, "id": "0b872fa3-e39f-4d27-9dda-6921e7f64094", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Created [https://www.googleapis.com/compute/v1/projects/statmike-mlops-349915/global/addresses/vertex-ai-peering-range].\n"]}], "source": ["!gcloud compute addresses create vertex-ai-peering-range \\\n", "    --global \\\n", "    --prefix-length=16 \\\n", "    --description=\"peering range for Google service\" \\\n", "    --network=$NETWORK_NAME \\\n", "    --purpose=VPC_PEERING"]}, {"cell_type": "markdown", "id": "c138cd37-1421-49ee-81fa-e4bc47f755b4", "metadata": {}, "source": ["Establish a peering connection between VPC host project (this one) and Google's Service Networking:"]}, {"cell_type": "code", "execution_count": 8, "id": "72671217-740a-4cb5-b721-d7ebc3618934", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Operation \"operations/pssn.p24-1026793852137-5fca5f21-7b10-472f-a2de-572bc616ae68\" finished successfully.\n"]}], "source": ["!gcloud services vpc-peerings connect \\\n", "    --service=servicenetworking.googleapis.com \\\n", "    --network=$NETWORK_NAME \\\n", "    --ranges=vertex-ai-peering-range \\\n", "    --project=$PROJECT_ID"]}, {"cell_type": "markdown", "id": "26a60553-d7a3-4c8d-8d33-5f945b7e7d18", "metadata": {}, "source": ["List peering connections:"]}, {"cell_type": "code", "execution_count": 9, "id": "23717992-5dd8-429a-a9ec-3a846061e528", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["NAME                              NETWORK  PEER_PROJECT           PEER_NETWORK       STACK_TYPE  PEER_MTU  IMPORT_CUSTOM_ROUTES  EXPORT_CUSTOM_ROUTES  STATE   STATE_DETAILS\n", "servicenetworking-googleapis-com  default  fae5c370cd2ce92a1p-tp  servicenetworking  IPV4_ONLY             False                 False                 ACTIVE  [2023-06-22T09:57:26.212-07:00]: Connected.\n"]}], "source": ["!gcloud compute networks peerings list --network $NETWORK_NAME"]}, {"cell_type": "markdown", "id": "3665bcf5-2e20-4c30-87e3-5618251ac690", "metadata": {}, "source": ["---\n", "## Example Workflow: Deploy Model to Private Endpoint and Request Prediction"]}, {"cell_type": "markdown", "id": "111b9c25-79bc-4000-bd1a-a22c5ee75967", "metadata": {}, "source": ["### Get Model From Vertex AI Model Registry\n", "\n", "Getting the model created by the notebook [05a - Vertex AI Custom Model - TensorFlow - Custom Job With Python File.ipynb](../05%20-%20TensorFlow/05a%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Custom%20Job%20With%20Python%20File.ipynb).\n", "\n", "Reference:\n", "- [aiplatform.Model()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n", "- Note that `model_name` is either the model id, not the display name."]}, {"cell_type": "code", "execution_count": 17, "id": "beca8561-5f88-48c7-bc14-480050d84f43", "metadata": {}, "outputs": [], "source": ["model = aiplatform.Model(model_name = 'model_05_05a')"]}, {"cell_type": "code", "execution_count": 26, "id": "e9136979-bfa0-4372-972b-02a9f359812b", "metadata": {}, "outputs": [{"data": {"text/plain": ["'projects/1026793852137/locations/us-central1/models/model_05_05a'"]}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": ["model.resource_name"]}, {"cell_type": "markdown", "id": "cc05c5b4-0d64-47a8-a070-50209abddde6", "metadata": {}, "source": ["### Create Private Endpoint\n", "\n", "Reference:\n", "- [aiplatform.PrivateEndpoint.create()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PrivateEndpoint#google_cloud_aiplatform_PrivateEndpoint_create)\n", "- Note that `network` is a full name where the project is represented by the project number rather than name. This can be retrieved from the model resource name."]}, {"cell_type": "code", "execution_count": 38, "id": "a83c07ff-d319-4952-9630-0bde3b994406", "metadata": {}, "outputs": [], "source": ["project_number = model.resource_name.split('/')[1]"]}, {"cell_type": "code", "execution_count": 39, "id": "684d227a-3a40-47e8-8584-e5d0f744dfe9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Creating PrivateEndpoint\n", "Create PrivateEndpoint backing LRO: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096/operations/2394302224361586688\n", "PrivateEndpoint created. Resource name: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n", "To use this PrivateEndpoint in another session:\n", "endpoint = aiplatform.PrivateEndpoint('projects/1026793852137/locations/us-central1/endpoints/4573084364199428096')\n"]}], "source": ["endpoint = aiplatform.PrivateEndpoint.create(\n", "    display_name = f'{SERIES}',\n", "    network = f'projects/{project_number}/global/networks/{NETWORK_NAME}'\n", ")"]}, {"cell_type": "code", "execution_count": 40, "id": "b8499ea8-496c-4976-a220-3fdfc1050b08", "metadata": {}, "outputs": [{"data": {"text/plain": ["'projects/1026793852137/global/networks/default'"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.network"]}, {"cell_type": "code", "execution_count": 41, "id": "a6c13c19-f745-44a5-93c1-838d8199cfba", "metadata": {}, "outputs": [{"data": {"text/plain": ["('4573084364199428096', 'dev')"]}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.name, endpoint.display_name"]}, {"cell_type": "markdown", "id": "af775da0-1807-4d26-92e5-1c5ec3002e06", "metadata": {}, "source": ["### Deploy Model To Endpoint\n", "\n", "**Note: This takes 15+ minutes to complete**\n", "\n", "Reference:\n", "- [aiplatform.PrivateEndpoint.deploy()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PrivateEndpoint#google_cloud_aiplatform_PrivateEndpoint_deploy)"]}, {"cell_type": "code", "execution_count": 42, "id": "5e273c49-8e65-492f-a6dc-de5bcdd6ba60", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Deploying Model projects/1026793852137/locations/us-central1/models/model_05_05a to PrivateEndpoint : projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n", "Deploy PrivateEndpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096/operations/7384290611488096256\n", "PrivateEndpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n"]}], "source": ["endpoint.deploy(\n", "    model = model,\n", "    deployed_model_display_name = model.display_name,\n", "    machine_type = DEPLOY_COMPUTE,\n", "    min_replica_count = 1,\n", "    max_replica_count = 1\n", ")"]}, {"cell_type": "markdown", "id": "7b6c0f2d-1741-4ba3-99a1-0d285972c123", "metadata": {}, "source": ["### Get Prediction\n", "\n", "Reference:\n", "- [aiplatform.PrivateEndpoint.predict()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PrivateEndpoint#google_cloud_aiplatform_PrivateEndpoint_predict)"]}, {"cell_type": "code", "execution_count": 49, "id": "aa598574-1a6c-4c6d-b239-6bd96354ed32", "metadata": {}, "outputs": [{"data": {"text/plain": ["Prediction(predictions=[[0.999771655, 0.000228400182]], deployed_model_id='8093340165314969600', model_version_id=None, model_resource_name=None, explanations=None)"]}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.predict(instances = newobs[0:1])"]}, {"cell_type": "markdown", "id": "05a9b469-fa8a-4f87-ba0c-113e3ed7aac1", "metadata": {}, "source": ["---\n", "## Example Workflow: Request Prediction From Existing Endpoint\n", "\n", "When the private endpoint already exists and has a deployed model the workflow is:\n"]}, {"cell_type": "markdown", "id": "bf284073-b603-47a3-bd6c-1467f2f408de", "metadata": {}, "source": ["### Get Private Endpoint\n", "\n", "Reference:\n", "- [aiplatform.PrivateEndpoint.list()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PrivateEndpoint#google_cloud_aiplatform_PrivateEndpoint_list)\n", "- To directly use `aiplatform.PrivateEndpoint` with `endpoint_name = ` which is of the form `projects/<project number>/locations/<region>/endpoints/<endpoint_id>` where `endpoint_id` is the assigned name, not display name, of the endpoint.\n", "- Rather than needing the exact `endpoint_id`, the method used below is to list all Private Endpoints with the known `display_name` as a filter.  Then, if found, take the first match."]}, {"cell_type": "code", "execution_count": 54, "id": "e2948dc0-7e0a-4b95-8fdc-37deb78dc1a0", "metadata": {}, "outputs": [], "source": ["endpoints = aiplatform.PrivateEndpoint.list(filter = f'display_name={SERIES}')"]}, {"cell_type": "code", "execution_count": 55, "id": "c201d677-cfee-4c7a-af98-4eb2b963c332", "metadata": {}, "outputs": [], "source": ["if endpoints: endpoint = endpoints[0]"]}, {"cell_type": "markdown", "id": "353e22a6-16f5-464c-be0f-8470f29902d9", "metadata": {}, "source": ["### Get Prediction\n", "\n", "Reference:\n", "- [aiplatform.PrivateEndpoint.predict()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PrivateEndpoint#google_cloud_aiplatform_PrivateEndpoint_predict)"]}, {"cell_type": "code", "execution_count": 56, "id": "ff296206-604a-4745-a38b-2cdeb3e1648e", "metadata": {}, "outputs": [{"data": {"text/plain": ["Prediction(predictions=[[0.999771655, 0.000228400182]], deployed_model_id='8093340165314969600', model_version_id=None, model_resource_name=None, explanations=None)"]}, "execution_count": 56, "metadata": {}, "output_type": "execute_result"}], "source": ["endpoint.predict(instances = newobs[0:1])"]}, {"cell_type": "markdown", "id": "5254b2e4-9ee3-4d50-8846-9ae151e933ee", "metadata": {}, "source": ["---\n", "## Cleanup"]}, {"cell_type": "code", "execution_count": 57, "id": "f60b092d-5284-4998-9872-8d169539f543", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Undeploying PrivateEndpoint model: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n", "Undeploy PrivateEndpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096/operations/6806703959277830144\n", "PrivateEndpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n", "Deleting PrivateEndpoint : projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n", "Delete PrivateEndpoint  backing LRO: projects/1026793852137/locations/us-central1/operations/8916640384700907520\n", "PrivateEndpoint deleted. . Resource name: projects/1026793852137/locations/us-central1/endpoints/4573084364199428096\n"]}], "source": ["# remove endpoint\n", "endpoint.delete(force = True)"]}, {"cell_type": "code", "execution_count": null, "id": "dfc390bb-9172-40d4-8fd8-c833f4942f31", "metadata": {}, "outputs": [], "source": []}], "metadata": {"environment": {"kernel": "python3", "name": "tf2-gpu.2-11.m104", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 5}