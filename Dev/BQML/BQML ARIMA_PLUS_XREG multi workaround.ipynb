{"cells": [{"cell_type": "markdown", "id": "f09daf3a-f312-41f9-9843-40b5905ea6a7", "metadata": {}, "source": ["\n", "# DEV NOTEBOOK\n", "\n", "**NOTE**\n", "This tip has been incoprorate into the ARIMA_PLUS_XREG notebook along with expanded examples.  Please see: [BQML Multivariate Forecasting with ARIMA+ XREG](../../Applied%20Forecasting/BQML%20Multivariate%20Forecasting%20with%20ARIMA+%20XREG.ipynb)\n", "\n", "# Using BQML ARIMA_PLUS_XREG With Multiple Time Series\n", "\n", "This repository contains a [series on forecasting methods in GCP](../../Applied%20Forecasting/readme.md)\n", "\n", "One of the methods covered is [BQML Multivariate Forecasting with ARIMA+ XREG](../../Applied%20Forecasting/BQML%20Multivariate%20Forecasting%20with%20ARIMA+%20XREG.ipynb).  While in preview (current day is April 6, 2023) this model type (`MODEL_TYPE = 'ARIMA_PLUS_XREG'`) fits one time series at a time. In contrast, the `MODEL_TYPE = 'ARIMA_PLUS'` for unvariate ARIMA based forcasting as the parameter `time_series_id_col` which allows the specification of column that contains groups of rows belonging to different time series.\n", "\n", "This short notebook present a temporary workaround for this.  The method is to create separate forcasting models for each time series.  This is done by using parameterize SQL queries launch from the Python Client for BigQuery.\n", "\n", "---\n", "\n", "**Prerequisites:**\n", "- [BigQuery Time Series Forecasting Data Review and Preparation](./BigQuery%20Time%20Series%20Forecasting%20Data%20Review%20and%20Preparation.ipynb)\n", "    - prepare data for this notebook"]}, {"cell_type": "markdown", "id": "aab18187-2b37-42ee-aa26-8710a704ad20", "metadata": {}, "source": ["---\n", "## Colab Setup\n", "\n", "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20Forecasting/BQML%20Multivariate%20Forecasting%20with%20ARIMA+%20XREG.ipynb) and run the cells in this section.  Otherwise, skip this section.\n", "\n", "This cell will authenticate to GCP (follow prompts in the popup)."]}, {"cell_type": "code", "execution_count": 1, "id": "aa67ade3-c3ca-4e7f-9d78-a50876716ca7", "metadata": {}, "outputs": [], "source": ["PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"]}, {"cell_type": "code", "execution_count": 473, "id": "faf688b0-241d-4e82-8dfb-4fd8c61d7e0b", "metadata": {}, "outputs": [], "source": ["try:\n", "    import google.colab\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    !gcloud config set project {PROJECT_ID}\n", "except Exception:\n", "    pass"]}, {"cell_type": "markdown", "id": "56ed0993-2b47-445a-8283-cf64015a8fc3", "metadata": {}, "source": ["---\n", "## Setup"]}, {"cell_type": "markdown", "id": "21b40abb-2470-4dcd-88f6-a3ab968d2205", "metadata": {}, "source": ["inputs:"]}, {"cell_type": "code", "execution_count": 13, "id": "46b2b0d2-4b65-438e-95aa-36ce6cb2ad9c", "metadata": {}, "outputs": [{"data": {"text/plain": ["'statmike-mlops-349915'"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["project = !gcloud config get-value project\n", "PROJECT_ID = project[0]\n", "PROJECT_ID"]}, {"cell_type": "code", "execution_count": 19, "id": "830b8a1d-a636-46f4-a2f8-36e9e2b67f18", "metadata": {}, "outputs": [], "source": ["REGION = 'us-central1'\n", "EXPERIMENT = 'bqml-arimaplusxreg'\n", "SERIES = 'applied-forecasting'\n", "\n", "BQ_PROJECT = PROJECT_ID\n", "BQ_DATASET = SERIES.replace('-','_')\n", "BQ_TABLE = 'forecasting-data_prepped'\n", "\n", "viz_limit = 12"]}, {"cell_type": "markdown", "id": "e8f542b6-3775-401f-a370-6ba6c0efea31", "metadata": {}, "source": ["packages:"]}, {"cell_type": "code", "execution_count": 44, "id": "69c01855-66c7-4762-8fb9-6cc735eb5faa", "metadata": {}, "outputs": [], "source": ["from google.cloud import bigquery\n", "\n", "import pandas as pd\n", "import numpy as np\n", "from datetime import datetime, timedelta\n", "\n", "import matplotlib.pyplot as plt\n", "import plotly.express as px\n", "import plotly.graph_objects as go\n", "\n", "from time import sleep"]}, {"cell_type": "markdown", "id": "f927535e-6de8-4669-93da-4c5e702b9085", "metadata": {}, "source": ["clients:"]}, {"cell_type": "code", "execution_count": 21, "id": "ea648069-dbe0-4246-8090-8c98ded35812", "metadata": {}, "outputs": [], "source": ["bq = bigquery.Client(project = PROJECT_ID)"]}, {"cell_type": "markdown", "id": "f992e9f4-e016-40c5-80ad-a4c133b44193", "metadata": {}, "source": ["---\n", "## Work Around"]}, {"cell_type": "markdown", "id": "c67e8172-c33a-4482-b1b9-dc636dc00535", "metadata": {}, "source": ["Define forecasting parameters:"]}, {"cell_type": "code", "execution_count": 38, "id": "092099c3-ffd5-4d67-9247-1e566efa7135", "metadata": {}, "outputs": [], "source": ["# CUSTOMIZE\n", "TARGET_COLUMN = 'num_trips'\n", "TIME_COLUMN = 'starttime'\n", "SERIES_COLUMN = 'start_station_name'\n", "SPLIT_COLUMN = 'splits'\n", "COVARIATE_COLUMNS = ['avg_tripduration', 'pct_subscriber', 'ratio_gender'] # could be empty\n", "\n", "# CUSTOMIZE\n", "FORECAST_GRANULARITY = 'DAILY' # the data preparation included preparing the data at this level\n", "FORECAST_HORIZON_LENGTH = 14\n", "FORECAST_TEST_LENGTH = 14 # the data preparation included setting this value for splits = TEST\n", "FORECAST_VALIDATE_LENGTH = 14 # the data preparation included setting this value for splits = VALIDATE"]}, {"cell_type": "markdown", "id": "4eb73b28-a7f0-4b62-9a35-c86e6d50d8da", "metadata": {}, "source": ["Retrieve a list of the time series id's"]}, {"cell_type": "code", "execution_count": 39, "id": "e4f89987-0285-432e-9815-854c1d2266c0", "metadata": {}, "outputs": [{"data": {"text/plain": ["['Central Park S & 6 Ave',\n", " 'Central Park West & W 72 St',\n", " 'Grand Army Plaza & Central Park S',\n", " 'W 82 St & Central Park West',\n", " 'Central Park West & W 100 St',\n", " 'Central Park West & W 85 St',\n", " 'Central Park North & Adam Clayton Powell Blvd',\n", " 'Central Park West & W 76 St',\n", " 'Central Park West & W 68 St',\n", " 'Central Park West & W 102 St',\n", " 'Central Park W & W 96 St',\n", " 'W 106 St & Central Park West']"]}, "execution_count": 39, "metadata": {}, "output_type": "execute_result"}], "source": ["query = f\"\"\"\n", "SELECT DISTINCT {SERIES_COLUMN}\n", "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n", "\"\"\"\n", "time_series_id_col = bq.query(query).to_dataframe()\n", "time_series_id_col = time_series_id_col[SERIES_COLUMN].tolist()\n", "time_series_id_col"]}, {"cell_type": "markdown", "id": "75f24eef-a36e-4e77-8f17-7abb70c4c85c", "metadata": {}, "source": ["Make a function that creates queries:"]}, {"cell_type": "code", "execution_count": 40, "id": "31ac02dc-1015-4492-bc8f-a57705f8031e", "metadata": {}, "outputs": [], "source": ["def make_model(ts_number, ts):\n", "    query = f\"\"\"\n", "        # create a model for {SERIES_COLUMN} = '{ts}'\n", "        CREATE OR REPLACE MODEL `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_arimaplusxreg_{ts_number}`\n", "        OPTIONS\n", "          (model_type = 'ARIMA_PLUS_XREG',\n", "           time_series_timestamp_col = '{TIME_COLUMN}',\n", "           time_series_data_col = '{TARGET_COLUMN}',\n", "           #time_series_id_col = '{SERIES_COLUMN}',\n", "           data_frequency = '{FORECAST_GRANULARITY}',\n", "           auto_arima_max_order = 5,\n", "           holiday_region = ['GLOBAL', 'US'],\n", "           horizon = {FORECAST_HORIZON_LENGTH} + {FORECAST_TEST_LENGTH}\n", "          ) AS\n", "        SELECT {TIME_COLUMN}, {TARGET_COLUMN},\n", "            {', '.join(COVARIATE_COLUMNS)}\n", "        FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n", "        WHERE {SPLIT_COLUMN} in ('TRAIN','VALIDATE')\n", "            AND {SERIES_COLUMN} = '{ts}'\n", "    \"\"\"\n", "    return query"]}, {"cell_type": "code", "execution_count": 41, "id": "2244184c-595a-46e9-8a1f-01ea38ee985f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "        # create a model for start_station_name = 'Central Park S & 6 Ave'\n", "        CREATE OR REPLACE MODEL `statmike-mlops-349915.applied_forecasting.forecasting-data_prepped_arimaplusxreg_0`\n", "        OPTIONS\n", "          (model_type = 'ARIMA_PLUS_XREG',\n", "           time_series_timestamp_col = 'starttime',\n", "           time_series_data_col = 'num_trips',\n", "           #time_series_id_col = 'start_station_name',\n", "           data_frequency = 'DAILY',\n", "           auto_arima_max_order = 5,\n", "           holiday_region = ['GLOBAL', 'US'],\n", "           horizon = 14 + 14\n", "          ) AS\n", "        SELECT starttime, num_trips,\n", "            avg_tripduration, pct_subscriber, ratio_gender\n", "        FROM `statmike-mlops-349915.applied_forecasting.forecasting-data_prepped`\n", "        WHERE splits in ('TRAIN','VALIDATE')\n", "            AND start_station_name = 'Central Park S & 6 Ave'\n", "    \n"]}], "source": ["print(make_model(0, time_series_id_col[0]))"]}, {"cell_type": "code", "execution_count": 46, "id": "a0d0adf5-104d-4fcd-9e27-40f5533032b5", "metadata": {}, "outputs": [], "source": ["bqml_jobs = [bq.query(query = make_model(tsi, ts)) for tsi, ts in enumerate(time_series_id_col)]"]}, {"cell_type": "code", "execution_count": 47, "id": "c22156fc-2dd3-4faf-9054-709a82304a68", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["waiting on all jobs to finish ... sleeping for 5s\n", "waiting on all jobs to finish ... sleeping for 5s\n", "waiting on all jobs to finish ... sleeping for 5s\n", "waiting on all jobs to finish ... sleeping for 5s\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n", "Completed with Errors =  None\n"]}], "source": ["while not all([job.done() for job in bqml_jobs]):\n", "    print('waiting on all jobs to finish ... sleeping for 5s')\n", "    sleep(5)\n", "for j, job in enumerate(bqml_jobs):\n", "    print('Completed with Errors = ', job.error_result)"]}, {"cell_type": "code", "execution_count": 48, "id": "bc6f3ad5-4851-41da-8f85-e1c388ec078f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Direct link to the models in BigQuery:\n", "https://console.cloud.google.com/bigquery?project=statmike-mlops-349915&ws=!1m5!1m4!5m3!1sstatmike-mlops-349915!2sapplied_forecasting!3sforecasting-data_prepped_arimaplusxreg_0\n"]}], "source": ["print(f'Direct link to the models in BigQuery:\\nhttps://console.cloud.google.com/bigquery?project={PROJECT_ID}&ws=!1m5!1m4!5m3!1s{PROJECT_ID}!2s{BQ_DATASET}!3s{BQ_TABLE}_arimaplusxreg_0')\n"]}, {"cell_type": "code", "execution_count": null, "id": "a454dde7-86ab-4a2f-869a-35a88824b8d8", "metadata": {}, "outputs": [], "source": []}], "metadata": {"environment": {"kernel": "python3", "name": "tf2-gpu.2-11.m104", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 5}